apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: a062dbc7342e261cec9fc094a94460acf639e78f12184cb5eeafc0a6a1927962
      cni.projectcalico.org/podIP: "null"
      cni.projectcalico.org/podIPs: "null"
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.2.2"
            ],
            "default": true,
            "dns": {}
        },{
            "name": "default/350vlan",
            "interface": "net1",
            "mac": "02:5e:f1:9f:d9:8d",
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks: '[{"name":"350vlan","namespace":"default","interface":"net1","cni-args":null}]'
    creationTimestamp: "2024-08-06T02:13:21Z"
    generateName: default350vlan-36667944-
    labels:
      batch.kubernetes.io/controller-uid: 5b1c2059-9ca9-4776-aed7-20f0208b2639
      batch.kubernetes.io/job-name: default350vlan-36667944
      controller-uid: 5b1c2059-9ca9-4776-aed7-20f0208b2639
      job-name: default350vlan-36667944
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:k8s.v1.cni.cncf.io/networks: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:batch.kubernetes.io/controller-uid: {}
            f:batch.kubernetes.io/job-name: {}
            f:controller-uid: {}
            f:job-name: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"5b1c2059-9ca9-4776-aed7-20f0208b2639"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"network-helper"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"DHCP_SERVER"}:
                  .: {}
                  f:name: {}
                k:{"name":"NAD_NETWORKS"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:13:21Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:27Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:31Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.2.2"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:31Z"
    name: default350vlan-36667944-9b2tt
    namespace: harvester-system
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: default350vlan-36667944
      uid: 5b1c2059-9ca9-4776-aed7-20f0208b2639
    resourceVersion: "26644"
    uid: 0db1d929-ab51-4d02-bf95-af1595d392d8
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: network.harvesterhci.io/mgmt
              operator: In
              values:
              - "true"
    containers:
    - env:
      - name: NAD_NETWORKS
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.annotations['k8s.v1.cni.cncf.io/networks']
      - name: DHCP_SERVER
      image: rancher/harvester-network-helper:v0.4.0
      imagePullPolicy: IfNotPresent
      name: network-helper
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-v2wgl
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev3
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-network-helper
    serviceAccountName: harvester-network-helper
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-v2wgl
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:21Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:29Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:29Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:21Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://027e7fd2844e842bf9810c0355fab361c107f7e362152e00665c9c3b9d21f427
      image: docker.io/rancher/harvester-network-helper:v0.4.0
      imageID: sha256:5320659f27001b64295082da1f788c3903ebbc0655871b05c82d7e2efba8670a
      lastState: {}
      name: network-helper
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://027e7fd2844e842bf9810c0355fab361c107f7e362152e00665c9c3b9d21f427
          exitCode: 0
          finishedAt: "2024-08-06T02:13:29Z"
          reason: Completed
          startedAt: "2024-08-06T02:13:28Z"
    hostIP: 10.10.110.61
    phase: Succeeded
    podIP: 10.52.2.2
    podIPs:
    - ip: 10.52.2.2
    qosClass: BestEffort
    startTime: "2024-08-06T02:13:21Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: d2c03e002d8fb2a1c7c116fe5a5535207eb744a6ab4b88d48f0a24239628e732
      cni.projectcalico.org/podIP: 10.52.0.33/32
      cni.projectcalico.org/podIPs: 10.52.0.33/32
      container.apparmor.security.beta.kubernetes.io/apiserver: unconfined
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.33"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T01:55:39Z"
    generateName: harvester-96fcbb748-
    labels:
      app.kubernetes.io/component: apiserver
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: harvester
      app.kubernetes.io/part-of: harvester
      app.kubernetes.io/version: v1.3.1
      helm.sh/chart: harvester-1.3.1
      helm.sh/release: harvester
      pod-template-hash: 96fcbb748
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:container.apparmor.security.beta.kubernetes.io/apiserver: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/name: {}
            f:app.kubernetes.io/part-of: {}
            f:app.kubernetes.io/version: {}
            f:helm.sh/chart: {}
            f:helm.sh/release: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"f1e8a9fb-b225-43f9-90f3-6278e60c7c45"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
            f:podAntiAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"apiserver"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"HARVESTER_DEBUG"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_SERVER_HTTP_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_SERVER_HTTPS_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HCI_MODE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"RANCHER_EMBEDDED"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":6060,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:capabilities:
                  .: {}
                  f:add: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.33"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:14:19Z"
    name: harvester-96fcbb748-562ns
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-96fcbb748
      uid: f1e8a9fb-b225-43f9-90f3-6278e60c7c45
    resourceVersion: "27925"
    uid: f69da336-6b02-4ec4-934b-202eb403808a
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: In
              values:
              - linux
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - harvester
            - key: app.kubernetes.io/component
              operator: In
              values:
              - apiserver
            - key: app.kubernetes.io/version
              operator: In
              values:
              - v1.3.1
          topologyKey: kubernetes.io/hostname
    containers:
    - env:
      - name: HARVESTER_SERVER_HTTPS_PORT
        value: "8443"
      - name: HARVESTER_DEBUG
        value: "false"
      - name: HARVESTER_SERVER_HTTP_PORT
        value: "0"
      - name: HCI_MODE
        value: "true"
      - name: RANCHER_EMBEDDED
        value: "true"
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/harvester:v1.3.1
      imagePullPolicy: IfNotPresent
      name: apiserver
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      - containerPort: 6060
        name: profile
        protocol: TCP
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
      securityContext:
        capabilities:
          add:
          - SYS_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cfshl
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester
    serviceAccountName: harvester
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-cfshl
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:14:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:14:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9cbb0798d9b8ff7684de7899150b0e585f14402b814b851e9fcb9a75a373376b
      image: docker.io/rancher/harvester:v1.3.1
      imageID: sha256:c61e8d5f76b77810dd9e1067c5f5a0e06ff785d060293cf0bcc791112272124e
      lastState:
        terminated:
          containerID: containerd://fb22aa2b5ebdd12e99168735f555d984fb0dd802a11e2b0aeeb7959b0c4fdca4
          exitCode: 2
          finishedAt: "2024-08-06T02:14:17Z"
          reason: Error
          startedAt: "2024-08-06T01:55:41Z"
      name: apiserver
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:14:18Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.33
    podIPs:
    - ip: 10.52.0.33
    qosClass: Burstable
    startTime: "2024-08-06T01:55:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 6f3a0307a8b5c3b2c6a4fca4a4afb85cf9e88ea9d3bdf26ee5d79d7dfa930c4e
      cni.projectcalico.org/podIP: 10.52.1.10/32
      cni.projectcalico.org/podIPs: 10.52.1.10/32
      container.apparmor.security.beta.kubernetes.io/apiserver: unconfined
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.1.10"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:11:20Z"
    generateName: harvester-96fcbb748-
    labels:
      app.kubernetes.io/component: apiserver
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: harvester
      app.kubernetes.io/part-of: harvester
      app.kubernetes.io/version: v1.3.1
      helm.sh/chart: harvester-1.3.1
      helm.sh/release: harvester
      pod-template-hash: 96fcbb748
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:container.apparmor.security.beta.kubernetes.io/apiserver: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/name: {}
            f:app.kubernetes.io/part-of: {}
            f:app.kubernetes.io/version: {}
            f:helm.sh/chart: {}
            f:helm.sh/release: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"f1e8a9fb-b225-43f9-90f3-6278e60c7c45"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
            f:podAntiAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"apiserver"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"HARVESTER_DEBUG"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_SERVER_HTTP_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_SERVER_HTTPS_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HCI_MODE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"RANCHER_EMBEDDED"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":6060,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:capabilities:
                  .: {}
                  f:add: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:11:20Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
      manager: kube-scheduler
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:20Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.1.10"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:42Z"
    name: harvester-96fcbb748-fr78b
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-96fcbb748
      uid: f1e8a9fb-b225-43f9-90f3-6278e60c7c45
    resourceVersion: "23498"
    uid: d2807d72-1d48-49c0-8e08-90488cb3f0a1
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: In
              values:
              - linux
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - harvester
            - key: app.kubernetes.io/component
              operator: In
              values:
              - apiserver
            - key: app.kubernetes.io/version
              operator: In
              values:
              - v1.3.1
          topologyKey: kubernetes.io/hostname
    containers:
    - env:
      - name: HARVESTER_SERVER_HTTPS_PORT
        value: "8443"
      - name: HARVESTER_DEBUG
        value: "false"
      - name: HARVESTER_SERVER_HTTP_PORT
        value: "0"
      - name: HCI_MODE
        value: "true"
      - name: RANCHER_EMBEDDED
        value: "true"
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/harvester:v1.3.1
      imagePullPolicy: IfNotPresent
      name: apiserver
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      - containerPort: 6060
        name: profile
        protocol: TCP
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
      securityContext:
        capabilities:
          add:
          - SYS_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5d59r
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester
    serviceAccountName: harvester
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-5d59r
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://70b11c50cf5eff1edbf1da45e17340b9056d159bbeb019721e5c31daed1d10b3
      image: docker.io/rancher/harvester:v1.3.1
      imageID: sha256:c61e8d5f76b77810dd9e1067c5f5a0e06ff785d060293cf0bcc791112272124e
      lastState: {}
      name: apiserver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:11:41Z"
    hostIP: 10.10.110.71
    phase: Running
    podIP: 10.52.1.10
    podIPs:
    - ip: 10.52.1.10
    qosClass: Burstable
    startTime: "2024-08-06T02:11:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: ed84a432caa35c4bd7e80ac13c132ce58013b7f6eca9840937e165b36e5aec24
      cni.projectcalico.org/podIP: 10.52.2.12/32
      cni.projectcalico.org/podIPs: 10.52.2.12/32
      container.apparmor.security.beta.kubernetes.io/apiserver: unconfined
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.2.12"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:13:12Z"
    generateName: harvester-96fcbb748-
    labels:
      app.kubernetes.io/component: apiserver
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: harvester
      app.kubernetes.io/part-of: harvester
      app.kubernetes.io/version: v1.3.1
      helm.sh/chart: harvester-1.3.1
      helm.sh/release: harvester
      pod-template-hash: 96fcbb748
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:container.apparmor.security.beta.kubernetes.io/apiserver: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/name: {}
            f:app.kubernetes.io/part-of: {}
            f:app.kubernetes.io/version: {}
            f:helm.sh/chart: {}
            f:helm.sh/release: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"f1e8a9fb-b225-43f9-90f3-6278e60c7c45"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
            f:podAntiAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"apiserver"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"HARVESTER_DEBUG"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_SERVER_HTTP_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_SERVER_HTTPS_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HCI_MODE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"RANCHER_EMBEDDED"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":6060,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:capabilities:
                  .: {}
                  f:add: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:13:11Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
      manager: kube-scheduler
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:12Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:32Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:32Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.2.12"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:33Z"
    name: harvester-96fcbb748-twtvt
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-96fcbb748
      uid: f1e8a9fb-b225-43f9-90f3-6278e60c7c45
    resourceVersion: "26702"
    uid: c7acede0-de4e-493f-b3fd-2e05fccc52ff
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: In
              values:
              - linux
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - harvester
            - key: app.kubernetes.io/component
              operator: In
              values:
              - apiserver
            - key: app.kubernetes.io/version
              operator: In
              values:
              - v1.3.1
          topologyKey: kubernetes.io/hostname
    containers:
    - env:
      - name: HARVESTER_SERVER_HTTPS_PORT
        value: "8443"
      - name: HARVESTER_DEBUG
        value: "false"
      - name: HARVESTER_SERVER_HTTP_PORT
        value: "0"
      - name: HCI_MODE
        value: "true"
      - name: RANCHER_EMBEDDED
        value: "true"
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/harvester:v1.3.1
      imagePullPolicy: IfNotPresent
      name: apiserver
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      - containerPort: 6060
        name: profile
        protocol: TCP
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
      securityContext:
        capabilities:
          add:
          - SYS_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-7gkfx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev3
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester
    serviceAccountName: harvester
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-7gkfx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:15Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:33Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:33Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:15Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://079f139758de46199f14c1a7e7a65d5ae263e0d79d72cbcae933836143d6eef0
      image: docker.io/rancher/harvester:v1.3.1
      imageID: sha256:c61e8d5f76b77810dd9e1067c5f5a0e06ff785d060293cf0bcc791112272124e
      lastState: {}
      name: apiserver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:13:33Z"
    hostIP: 10.10.110.61
    phase: Running
    podIP: 10.52.2.12
    podIPs:
    - ip: 10.52.2.12
    qosClass: Burstable
    startTime: "2024-08-06T02:13:15Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 516644bd724c324ecec874122ba2be835fa2caf9100d26d4172d006e4f239b6d
      cni.projectcalico.org/podIP: 10.52.0.35/32
      cni.projectcalico.org/podIPs: 10.52.0.35/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.35"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T01:55:39Z"
    generateName: harvester-load-balancer-54cd9754dc-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-load-balancer
      pod-template-hash: 54cd9754dc
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"c4795838-0249-42a3-9c33-34046d41d949"}: {}
        f:spec:
          f:containers:
            k:{"name":"harvester-load-balancer"}:
              .: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.35"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:42Z"
    name: harvester-load-balancer-54cd9754dc-jbvh5
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-load-balancer-54cd9754dc
      uid: c4795838-0249-42a3-9c33-34046d41d949
    resourceVersion: "4914"
    uid: cf7c24d4-978e-4116-8fdf-3b06433f7605
  spec:
    containers:
    - command:
      - harvester-load-balancer
      image: rancher/harvester-load-balancer:v0.3.0
      imagePullPolicy: IfNotPresent
      name: harvester-load-balancer
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 64Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rjzz5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-load-balancer
    serviceAccountName: harvester-load-balancer
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-rjzz5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://ff490212a2df0635c3f2c4851a11060edc4a31ec59f1f9d7a642ce66aab25498
      image: docker.io/rancher/harvester-load-balancer:v0.3.0
      imageID: sha256:945e0ec0170795e781ba23d9d6ba1f8316cf90a12512867c0ea448698c0ad83a
      lastState: {}
      name: harvester-load-balancer
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:55:42Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.35
    podIPs:
    - ip: 10.52.0.35
    qosClass: Burstable
    startTime: "2024-08-06T01:55:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: b0a01685a5b793b2042a39837116e54535d4d04e85c8f2d0fd7ad1c77a07e2eb
      cni.projectcalico.org/podIP: 10.52.0.34/32
      cni.projectcalico.org/podIPs: 10.52.0.34/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.34"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T01:55:39Z"
    generateName: harvester-load-balancer-webhook-c8699b786-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-load-balancer-webhook
      pod-template-hash: c8699b786
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"22750d76-f079-4260-b7b1-a64fae574a11"}: {}
        f:spec:
          f:containers:
            k:{"name":"harvester-load-balancer-webhook"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"HARVESTER_CONTROLLER_USER_NAME"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_WEBHOOK_SERVER_HTTPS_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.34"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:42Z"
    name: harvester-load-balancer-webhook-c8699b786-x9xck
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-load-balancer-webhook-c8699b786
      uid: 22750d76-f079-4260-b7b1-a64fae574a11
    resourceVersion: "4910"
    uid: d32a1e63-9858-4229-97af-50954a757908
  spec:
    containers:
    - command:
      - harvester-load-balancer-webhook
      env:
      - name: HARVESTER_WEBHOOK_SERVER_HTTPS_PORT
        value: "8443"
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: HARVESTER_CONTROLLER_USER_NAME
        value: system:serviceaccount:harvester-system:harvester-load-balancer-webhook
      image: rancher/harvester-load-balancer-webhook:v0.3.0
      imagePullPolicy: IfNotPresent
      name: harvester-load-balancer-webhook
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 512Mi
        requests:
          cpu: 10m
          memory: 128Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-47zdq
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-load-balancer-webhook
    serviceAccountName: harvester-load-balancer-webhook
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-47zdq
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://02925d28f407f60c04a00d1adc70c0dc7909028f4c8a634c2c83d256cb2f066f
      image: docker.io/rancher/harvester-load-balancer-webhook:v0.3.0
      imageID: sha256:d11ba2973ed49d150147c212a19ee70aff26c14b4f7ff78f4ec821fda051db95
      lastState: {}
      name: harvester-load-balancer-webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:55:42Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.34
    podIPs:
    - ip: 10.52.0.34
    qosClass: Burstable
    startTime: "2024-08-06T01:55:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-06T02:15:35Z"
    generateName: harvester-network-controller-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-network-controller
      controller-revision-hash: 5c94bdddb9
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"2a999ca8-60ef-46d1-a406-78d20116c186"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-network"}:
              .: {}
              f:args: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"NODENAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/dev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/lib/modules"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"dev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"modules"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:15:35Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.10.110.232"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:15:39Z"
    name: harvester-network-controller-4jbzn
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-network-controller
      uid: 2a999ca8-60ef-46d1-a406-78d20116c186
    resourceVersion: "29807"
    uid: e9045c25-d850-4181-bd45-d2537e482521
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev7
    containers:
    - args:
      - agent
      command:
      - harvester-network-controller
      env:
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/harvester-network-controller:v0.4.0
      imagePullPolicy: IfNotPresent
      name: harvester-network
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 64Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /dev
        name: dev
      - mountPath: /lib/modules
        name: modules
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zrdpf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: harvesterdev7
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-network-controller
    serviceAccountName: harvester-network-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /dev
        type: "null"
      name: dev
    - hostPath:
        path: /lib/modules
        type: "null"
      name: modules
    - name: kube-api-access-zrdpf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:35Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:39Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:39Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:35Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4972fe419a0a31fe1979cd7cdd19921786e59327afb3dc4cb78879fc65865a4a
      image: docker.io/rancher/harvester-network-controller:v0.4.0
      imageID: sha256:b4aa17f3b8e20edf7ca6b6095e9520eabea5ca16fabfe1255112cd9dfc0804d2
      lastState: {}
      name: harvester-network
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:15:39Z"
    hostIP: 10.10.110.232
    phase: Running
    podIP: 10.10.110.232
    podIPs:
    - ip: 10.10.110.232
    qosClass: Burstable
    startTime: "2024-08-06T02:15:35Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-06T02:11:24Z"
    generateName: harvester-network-controller-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-network-controller
      controller-revision-hash: 5c94bdddb9
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"2a999ca8-60ef-46d1-a406-78d20116c186"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-network"}:
              .: {}
              f:args: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"NODENAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/dev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/lib/modules"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"dev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"modules"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:11:24Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.10.110.71"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:27Z"
    name: harvester-network-controller-dsgp4
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-network-controller
      uid: 2a999ca8-60ef-46d1-a406-78d20116c186
    resourceVersion: "23021"
    uid: 0c6d8975-441b-46a7-bb88-10b7e2d30bc6
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev2
    containers:
    - args:
      - agent
      command:
      - harvester-network-controller
      env:
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/harvester-network-controller:v0.4.0
      imagePullPolicy: IfNotPresent
      name: harvester-network
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 64Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /dev
        name: dev
      - mountPath: /lib/modules
        name: modules
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4qrht
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: harvesterdev2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-network-controller
    serviceAccountName: harvester-network-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /dev
        type: "null"
      name: dev
    - hostPath:
        path: /lib/modules
        type: "null"
      name: modules
    - name: kube-api-access-4qrht
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:27Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:27Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://cb3fecefe2e6b934aa22122828b740a2d92c428e13a15f08a42114d567a36852
      image: docker.io/rancher/harvester-network-controller:v0.4.0
      imageID: sha256:b4aa17f3b8e20edf7ca6b6095e9520eabea5ca16fabfe1255112cd9dfc0804d2
      lastState: {}
      name: harvester-network
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:11:26Z"
    hostIP: 10.10.110.71
    phase: Running
    podIP: 10.10.110.71
    podIPs:
    - ip: 10.10.110.71
    qosClass: Burstable
    startTime: "2024-08-06T02:11:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-06T01:55:39Z"
    generateName: harvester-network-controller-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-network-controller
      controller-revision-hash: 5c94bdddb9
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"2a999ca8-60ef-46d1-a406-78d20116c186"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-network"}:
              .: {}
              f:args: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"NODENAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/dev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/lib/modules"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"dev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"modules"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.10.110.11"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:41Z"
    name: harvester-network-controller-jnm84
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-network-controller
      uid: 2a999ca8-60ef-46d1-a406-78d20116c186
    resourceVersion: "4855"
    uid: 2620cac8-6fd8-4f34-aac5-5253b08eadbe
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev1
    containers:
    - args:
      - agent
      command:
      - harvester-network-controller
      env:
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/harvester-network-controller:v0.4.0
      imagePullPolicy: IfNotPresent
      name: harvester-network
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 64Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /dev
        name: dev
      - mountPath: /lib/modules
        name: modules
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-qcmkl
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-network-controller
    serviceAccountName: harvester-network-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /dev
        type: "null"
      name: dev
    - hostPath:
        path: /lib/modules
        type: "null"
      name: modules
    - name: kube-api-access-qcmkl
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:41Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:41Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://45d01d70323e16dca32532e4870ec6a75a067325b9a03b38ccce62319c4f20b7
      image: docker.io/rancher/harvester-network-controller:v0.4.0
      imageID: sha256:b4aa17f3b8e20edf7ca6b6095e9520eabea5ca16fabfe1255112cd9dfc0804d2
      lastState: {}
      name: harvester-network
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:55:41Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.10.110.11
    podIPs:
    - ip: 10.10.110.11
    qosClass: Burstable
    startTime: "2024-08-06T01:55:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-06T01:55:39Z"
    generateName: harvester-network-controller-manager-b69bf6b69-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-network-controller-manager
      pod-template-hash: b69bf6b69
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"c4d98230-1054-40f9-b162-597cc217f733"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
            f:podAntiAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-network-manager"}:
              .: {}
              f:args: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:capabilities:
                  .: {}
                  f:add: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.10.110.11"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:41Z"
    name: harvester-network-controller-manager-b69bf6b69-g57bb
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-network-controller-manager-b69bf6b69
      uid: c4d98230-1054-40f9-b162-597cc217f733
    resourceVersion: "4853"
    uid: 444fd25c-3142-40d8-85a1-3fac51cc3f0a
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: In
              values:
              - linux
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - harvester-network-controller-manager
          topologyKey: kubernetes.io/hostname
    containers:
    - args:
      - manager
      - --enable-vip-controller
      - --helper-image=rancher/harvester-network-helper:v0.4.0
      command:
      - harvester-network-controller
      env:
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/harvester-network-controller:v0.4.0
      imagePullPolicy: IfNotPresent
      name: harvester-network-manager
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 64Mi
      securityContext:
        capabilities:
          add:
          - NET_RAW
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-m8svf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-network-controller
    serviceAccountName: harvester-network-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-m8svf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:41Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:41Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c67b1ed42c979d64d01436084b41f97c5c7c4284108830e8bb9e6b29366cfdb1
      image: docker.io/rancher/harvester-network-controller:v0.4.0
      imageID: sha256:b4aa17f3b8e20edf7ca6b6095e9520eabea5ca16fabfe1255112cd9dfc0804d2
      lastState: {}
      name: harvester-network-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:55:41Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.10.110.11
    podIPs:
    - ip: 10.10.110.11
    qosClass: Burstable
    startTime: "2024-08-06T01:55:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-06T02:11:20Z"
    generateName: harvester-network-controller-manager-b69bf6b69-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-network-controller-manager
      pod-template-hash: b69bf6b69
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"c4d98230-1054-40f9-b162-597cc217f733"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
            f:podAntiAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-network-manager"}:
              .: {}
              f:args: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:capabilities:
                  .: {}
                  f:add: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:11:20Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
      manager: kube-scheduler
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:20Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.10.110.71"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:27Z"
    name: harvester-network-controller-manager-b69bf6b69-lk2wh
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-network-controller-manager-b69bf6b69
      uid: c4d98230-1054-40f9-b162-597cc217f733
    resourceVersion: "23019"
    uid: 5e0f0047-dbde-4d61-b696-11cc8b9f4764
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: In
              values:
              - linux
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - harvester-network-controller-manager
          topologyKey: kubernetes.io/hostname
    containers:
    - args:
      - manager
      - --enable-vip-controller
      - --helper-image=rancher/harvester-network-helper:v0.4.0
      command:
      - harvester-network-controller
      env:
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/harvester-network-controller:v0.4.0
      imagePullPolicy: IfNotPresent
      name: harvester-network-manager
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 64Mi
      securityContext:
        capabilities:
          add:
          - NET_RAW
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zkjxv
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: harvesterdev2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-network-controller
    serviceAccountName: harvester-network-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-zkjxv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:27Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:27Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://498bf96e2c459855f7cc016d7fb0083a73fa7e0fd26f50cfc9b04e69853a2860
      image: docker.io/rancher/harvester-network-controller:v0.4.0
      imageID: sha256:b4aa17f3b8e20edf7ca6b6095e9520eabea5ca16fabfe1255112cd9dfc0804d2
      lastState: {}
      name: harvester-network-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:11:26Z"
    hostIP: 10.10.110.71
    phase: Running
    podIP: 10.10.110.71
    podIPs:
    - ip: 10.10.110.71
    qosClass: Burstable
    startTime: "2024-08-06T02:11:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-06T02:13:16Z"
    generateName: harvester-network-controller-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-network-controller
      controller-revision-hash: 5c94bdddb9
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"2a999ca8-60ef-46d1-a406-78d20116c186"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-network"}:
              .: {}
              f:args: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"NODENAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/dev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/lib/modules"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"dev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"modules"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:13:16Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.10.110.61"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:18Z"
    name: harvester-network-controller-qsxvn
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-network-controller
      uid: 2a999ca8-60ef-46d1-a406-78d20116c186
    resourceVersion: "26163"
    uid: ac91191c-26cc-475b-9e2e-4e644e48b407
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev3
    containers:
    - args:
      - agent
      command:
      - harvester-network-controller
      env:
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/harvester-network-controller:v0.4.0
      imagePullPolicy: IfNotPresent
      name: harvester-network
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 64Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /dev
        name: dev
      - mountPath: /lib/modules
        name: modules
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xh6fh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: harvesterdev3
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-network-controller
    serviceAccountName: harvester-network-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /dev
        type: "null"
      name: dev
    - hostPath:
        path: /lib/modules
        type: "null"
      name: modules
    - name: kube-api-access-xh6fh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:16Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:16Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://bc95b901df84050cb3a97846e8651313f1c2a085ea3e0b4055bb494cbf27b253
      image: docker.io/rancher/harvester-network-controller:v0.4.0
      imageID: sha256:b4aa17f3b8e20edf7ca6b6095e9520eabea5ca16fabfe1255112cd9dfc0804d2
      lastState: {}
      name: harvester-network
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:13:18Z"
    hostIP: 10.10.110.61
    phase: Running
    podIP: 10.10.110.61
    podIPs:
    - ip: 10.10.110.61
    qosClass: Burstable
    startTime: "2024-08-06T02:13:16Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 195717c154084db0f99e6bcc3fb5812de8d1d0ac706364d9dda493d924db8c8a
      cni.projectcalico.org/podIP: 10.52.0.32/32
      cni.projectcalico.org/podIPs: 10.52.0.32/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.32"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T01:55:39Z"
    generateName: harvester-network-webhook-7b98f8cd98-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-network-webhook
      pod-template-hash: 7b98f8cd98
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"a586f9c6-eb23-485b-a593-8df798729f95"}: {}
        f:spec:
          f:containers:
            k:{"name":"harvester-network-webhook"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.32"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:42Z"
    name: harvester-network-webhook-7b98f8cd98-fj7dq
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-network-webhook-7b98f8cd98
      uid: a586f9c6-eb23-485b-a593-8df798729f95
    resourceVersion: "4927"
    uid: d6490a22-2f07-4fbc-90ee-c9af96c19651
  spec:
    containers:
    - command:
      - harvester-network-webhook
      env:
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/harvester-network-webhook:v0.4.0
      imagePullPolicy: IfNotPresent
      name: harvester-network-webhook
      resources:
        limits:
          cpu: 200m
          memory: 256Mi
        requests:
          cpu: 10m
          memory: 64Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-smqjp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-network-webhook
    serviceAccountName: harvester-network-webhook
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-smqjp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://fbe7cbb5daa5ec98cb75dd79b6b3f1b9511cfc119853e0e0939e923caefd43fc
      image: docker.io/rancher/harvester-network-webhook:v0.4.0
      imageID: sha256:d7f2476e98bb9090c477d4410e8b1688b9c52491ba3fa8dff9b43d9d73f7b544
      lastState: {}
      name: harvester-network-webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:55:41Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.32
    podIPs:
    - ip: 10.52.0.32
    qosClass: Burstable
    startTime: "2024-08-06T01:55:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-06T01:58:46Z"
    generateName: harvester-node-disk-manager-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-node-disk-manager
      controller-revision-hash: cf749d96c
      pod-template-generation: "2"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"636d87cd-54c9-4129-b07c-b419cd0d56f4"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-node-disk-manager"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"LONGHORN_NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NDM_AUTO_PROVISION_FILTER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NDM_LABEL_FILTER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/dev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/run/udev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/sys"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"host-dev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-run-udev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-sys"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:58:46Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.10.110.11"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:58:48Z"
    name: harvester-node-disk-manager-28xc4
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-node-disk-manager
      uid: 636d87cd-54c9-4129-b07c-b419cd0d56f4
    resourceVersion: "10867"
    uid: 087f151a-6c69-4ae5-a120-094a0e1890a2
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev1
    containers:
    - command:
      - node-disk-manager
      env:
      - name: NDM_LABEL_FILTER
        value: COS_*,HARV_*
      - name: NDM_AUTO_PROVISION_FILTER
        value: /dev/sd*
      - name: LONGHORN_NAMESPACE
        value: longhorn-system
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: rancher/harvester-node-disk-manager:v0.6.3
      imagePullPolicy: IfNotPresent
      name: harvester-node-disk-manager
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: host-proc
        readOnly: true
      - mountPath: /run/udev
        name: host-run-udev
        readOnly: true
      - mountPath: /dev
        name: host-dev
        readOnly: true
      - mountPath: /sys
        name: host-sys
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-nf4tw
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-node-disk-manager
    serviceAccountName: harvester-node-disk-manager
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: Directory
      name: host-proc
    - hostPath:
        path: /run/udev
        type: Directory
      name: host-run-udev
    - hostPath:
        path: /dev
        type: Directory
      name: host-dev
    - hostPath:
        path: /sys
        type: Directory
      name: host-sys
    - name: kube-api-access-nf4tw
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:58:46Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:58:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:58:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:58:46Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://54815284b733931b518eb5d9e278c9e811fd837ad007a5229ccea230f62f50fa
      image: docker.io/rancher/harvester-node-disk-manager:v0.6.3
      imageID: sha256:e941b03ff4e168cd50be6a48cce4e4f4ac71e11f43e0fad16bb765277a08226b
      lastState: {}
      name: harvester-node-disk-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:58:47Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.10.110.11
    podIPs:
    - ip: 10.10.110.11
    qosClass: BestEffort
    startTime: "2024-08-06T01:58:46Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-06T02:11:24Z"
    generateName: harvester-node-disk-manager-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-node-disk-manager
      controller-revision-hash: cf749d96c
      pod-template-generation: "2"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"636d87cd-54c9-4129-b07c-b419cd0d56f4"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-node-disk-manager"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"LONGHORN_NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NDM_AUTO_PROVISION_FILTER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NDM_LABEL_FILTER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/dev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/run/udev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/sys"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"host-dev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-run-udev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-sys"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:11:24Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.10.110.71"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:27Z"
    name: harvester-node-disk-manager-4bcf5
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-node-disk-manager
      uid: 636d87cd-54c9-4129-b07c-b419cd0d56f4
    resourceVersion: "23016"
    uid: 8ca86fba-b064-486b-a361-81eca9b50f66
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev2
    containers:
    - command:
      - node-disk-manager
      env:
      - name: NDM_LABEL_FILTER
        value: COS_*,HARV_*
      - name: NDM_AUTO_PROVISION_FILTER
        value: /dev/sd*
      - name: LONGHORN_NAMESPACE
        value: longhorn-system
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: rancher/harvester-node-disk-manager:v0.6.3
      imagePullPolicy: IfNotPresent
      name: harvester-node-disk-manager
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: host-proc
        readOnly: true
      - mountPath: /run/udev
        name: host-run-udev
        readOnly: true
      - mountPath: /dev
        name: host-dev
        readOnly: true
      - mountPath: /sys
        name: host-sys
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-gqk5p
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: harvesterdev2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-node-disk-manager
    serviceAccountName: harvester-node-disk-manager
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: Directory
      name: host-proc
    - hostPath:
        path: /run/udev
        type: Directory
      name: host-run-udev
    - hostPath:
        path: /dev
        type: Directory
      name: host-dev
    - hostPath:
        path: /sys
        type: Directory
      name: host-sys
    - name: kube-api-access-gqk5p
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:27Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:27Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://276733ca2038c356c741d7c73d044fb6a41dfb570c1872a5577d0981a0925d09
      image: docker.io/rancher/harvester-node-disk-manager:v0.6.3
      imageID: sha256:e941b03ff4e168cd50be6a48cce4e4f4ac71e11f43e0fad16bb765277a08226b
      lastState: {}
      name: harvester-node-disk-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:11:26Z"
    hostIP: 10.10.110.71
    phase: Running
    podIP: 10.10.110.71
    podIPs:
    - ip: 10.10.110.71
    qosClass: BestEffort
    startTime: "2024-08-06T02:11:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-06T02:13:16Z"
    generateName: harvester-node-disk-manager-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-node-disk-manager
      controller-revision-hash: cf749d96c
      pod-template-generation: "2"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"636d87cd-54c9-4129-b07c-b419cd0d56f4"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-node-disk-manager"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"LONGHORN_NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NDM_AUTO_PROVISION_FILTER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NDM_LABEL_FILTER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/dev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/run/udev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/sys"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"host-dev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-run-udev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-sys"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:13:15Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.10.110.61"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:19Z"
    name: harvester-node-disk-manager-vpcv4
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-node-disk-manager
      uid: 636d87cd-54c9-4129-b07c-b419cd0d56f4
    resourceVersion: "26197"
    uid: 4d49c1e6-e521-4183-b3ef-7a4fcec0e0cc
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev3
    containers:
    - command:
      - node-disk-manager
      env:
      - name: NDM_LABEL_FILTER
        value: COS_*,HARV_*
      - name: NDM_AUTO_PROVISION_FILTER
        value: /dev/sd*
      - name: LONGHORN_NAMESPACE
        value: longhorn-system
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: rancher/harvester-node-disk-manager:v0.6.3
      imagePullPolicy: IfNotPresent
      name: harvester-node-disk-manager
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: host-proc
        readOnly: true
      - mountPath: /run/udev
        name: host-run-udev
        readOnly: true
      - mountPath: /dev
        name: host-dev
        readOnly: true
      - mountPath: /sys
        name: host-sys
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4mddb
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: harvesterdev3
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-node-disk-manager
    serviceAccountName: harvester-node-disk-manager
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: Directory
      name: host-proc
    - hostPath:
        path: /run/udev
        type: Directory
      name: host-run-udev
    - hostPath:
        path: /dev
        type: Directory
      name: host-dev
    - hostPath:
        path: /sys
        type: Directory
      name: host-sys
    - name: kube-api-access-4mddb
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:16Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:19Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:19Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:16Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://df74e0c06c0ad2e3ab5b50ae862ece01f13c45b250681c3066029dbc8c629f7a
      image: docker.io/rancher/harvester-node-disk-manager:v0.6.3
      imageID: sha256:e941b03ff4e168cd50be6a48cce4e4f4ac71e11f43e0fad16bb765277a08226b
      lastState:
        terminated:
          containerID: containerd://f6a5b07bbd4c8314c8444a29d2780bd1d344c2fb3bbd136b055889dcaf397c68
          exitCode: 128
          finishedAt: "2024-08-06T02:13:18Z"
          message: 'failed to create containerd task: failed to create shim task:
            OCI runtime create failed: runc create failed: unable to start container
            process: error during container init: error mounting "/var/lib/kubelet/pods/4d49c1e6-e521-4183-b3ef-7a4fcec0e0cc/containers/harvester-node-disk-manager/23f04db8"
            to rootfs at "/dev/termination-log": open /run/k3s/containerd/io.containerd.runtime.v2.task/k8s.io/f6a5b07bbd4c8314c8444a29d2780bd1d344c2fb3bbd136b055889dcaf397c68/rootfs/dev/termination-log:
            read-only file system: unknown'
          reason: StartError
          startedAt: "1970-01-01T00:00:00Z"
      name: harvester-node-disk-manager
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:13:18Z"
    hostIP: 10.10.110.61
    phase: Running
    podIP: 10.10.110.61
    podIPs:
    - ip: 10.10.110.61
    qosClass: BestEffort
    startTime: "2024-08-06T02:13:16Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-06T02:15:35Z"
    generateName: harvester-node-disk-manager-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-node-disk-manager
      controller-revision-hash: cf749d96c
      pod-template-generation: "2"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"636d87cd-54c9-4129-b07c-b419cd0d56f4"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-node-disk-manager"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"LONGHORN_NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NDM_AUTO_PROVISION_FILTER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NDM_LABEL_FILTER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/dev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/run/udev"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/sys"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"host-dev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-run-udev"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-sys"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:15:35Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.10.110.232"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:15:40Z"
    name: harvester-node-disk-manager-zhxfv
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-node-disk-manager
      uid: 636d87cd-54c9-4129-b07c-b419cd0d56f4
    resourceVersion: "29833"
    uid: ba3fb72e-cdb5-447e-b0f7-211128247e54
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev7
    containers:
    - command:
      - node-disk-manager
      env:
      - name: NDM_LABEL_FILTER
        value: COS_*,HARV_*
      - name: NDM_AUTO_PROVISION_FILTER
        value: /dev/sd*
      - name: LONGHORN_NAMESPACE
        value: longhorn-system
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: rancher/harvester-node-disk-manager:v0.6.3
      imagePullPolicy: IfNotPresent
      name: harvester-node-disk-manager
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: host-proc
        readOnly: true
      - mountPath: /run/udev
        name: host-run-udev
        readOnly: true
      - mountPath: /dev
        name: host-dev
        readOnly: true
      - mountPath: /sys
        name: host-sys
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-nctlb
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: harvesterdev7
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-node-disk-manager
    serviceAccountName: harvester-node-disk-manager
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: Directory
      name: host-proc
    - hostPath:
        path: /run/udev
        type: Directory
      name: host-run-udev
    - hostPath:
        path: /dev
        type: Directory
      name: host-dev
    - hostPath:
        path: /sys
        type: Directory
      name: host-sys
    - name: kube-api-access-nctlb
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:35Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:35Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9a25f41c44bbbcab566a659275f848dcde2c332d4af88637baff05e66b9eb6b3
      image: docker.io/rancher/harvester-node-disk-manager:v0.6.3
      imageID: sha256:e941b03ff4e168cd50be6a48cce4e4f4ac71e11f43e0fad16bb765277a08226b
      lastState: {}
      name: harvester-node-disk-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:15:39Z"
    hostIP: 10.10.110.232
    phase: Running
    podIP: 10.10.110.232
    podIPs:
    - ip: 10.10.110.232
    qosClass: BestEffort
    startTime: "2024-08-06T02:15:35Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 57823668a09fdbb3263da4b913573f31f424dfc8287e42776872fa3a7c1c7ece
      cni.projectcalico.org/podIP: 10.52.3.5/32
      cni.projectcalico.org/podIPs: 10.52.3.5/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.3.5"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:15:35Z"
    generateName: harvester-node-manager-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-node-manager
      controller-revision-hash: 5557649fd7
      name: harvester-node-manager
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:name: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"4d56340c-2162-4d7d-b7cd-99d82280b9ad"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"node-manager"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"HOST_PROC"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODENAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/host/etc/systemd"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/oem"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/sys/kernel/mm/ksm"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/dbus/system_bus_socket"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"dbus-socket"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-oem"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-systemd"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"ksm"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:15:35Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:15:50Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:15:50Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.3.5"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:15:57Z"
    name: harvester-node-manager-65cs8
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-node-manager
      uid: 4d56340c-2162-4d7d-b7cd-99d82280b9ad
    resourceVersion: "30245"
    uid: e140b298-0027-48a0-9b2f-07f322a3e261
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev7
    containers:
    - command:
      - harvester-node-manager
      env:
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: HOST_PROC
        value: /host/proc
      image: rancher/harvester-node-manager:v0.2.1
      imagePullPolicy: IfNotPresent
      name: node-manager
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 64Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /sys/kernel/mm/ksm
        name: ksm
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /var/run/dbus/system_bus_socket
        name: dbus-socket
        readOnly: true
      - mountPath: /host/etc/systemd
        name: host-systemd
      - mountPath: /host/oem
        name: host-oem
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-2mxdp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev7
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-node-manager
    serviceAccountName: harvester-node-manager
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /sys/kernel/mm/ksm
        type: "null"
      name: ksm
    - hostPath:
        path: /proc
        type: "null"
      name: proc
    - hostPath:
        path: /var/run/dbus/system_bus_socket
        type: "null"
      name: dbus-socket
    - hostPath:
        path: /etc/systemd
        type: "null"
      name: host-systemd
    - hostPath:
        path: /oem
        type: "null"
      name: host-oem
    - name: kube-api-access-2mxdp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:35Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:57Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:57Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:35Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://0b6b6017ac1a7a943049c5693c082c3b5ffd596a264ab247ce2602f0eae6529e
      image: docker.io/rancher/harvester-node-manager:v0.2.1
      imageID: sha256:8e1a6a5cff4e304ef53711ca49183f7877417aba9dbdab8da113862d81b195d3
      lastState: {}
      name: node-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:15:56Z"
    hostIP: 10.10.110.232
    phase: Running
    podIP: 10.52.3.5
    podIPs:
    - ip: 10.52.3.5
    qosClass: Burstable
    startTime: "2024-08-06T02:15:35Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: b7ccf9f32aca266a4a1bf870d4ce930d7d71d919a812b7c0accb54cc84d69172
      cni.projectcalico.org/podIP: 10.52.1.9/32
      cni.projectcalico.org/podIPs: 10.52.1.9/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.1.9"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:11:24Z"
    generateName: harvester-node-manager-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-node-manager
      controller-revision-hash: 5557649fd7
      name: harvester-node-manager
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:name: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"4d56340c-2162-4d7d-b7cd-99d82280b9ad"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"node-manager"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"HOST_PROC"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODENAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/host/etc/systemd"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/oem"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/sys/kernel/mm/ksm"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/dbus/system_bus_socket"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"dbus-socket"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-oem"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-systemd"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"ksm"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:11:24Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.1.9"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:43Z"
    name: harvester-node-manager-6x48k
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-node-manager
      uid: 4d56340c-2162-4d7d-b7cd-99d82280b9ad
    resourceVersion: "23539"
    uid: 9efae661-157c-4367-8bf9-30a2a3295701
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev2
    containers:
    - command:
      - harvester-node-manager
      env:
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: HOST_PROC
        value: /host/proc
      image: rancher/harvester-node-manager:v0.2.1
      imagePullPolicy: IfNotPresent
      name: node-manager
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 64Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /sys/kernel/mm/ksm
        name: ksm
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /var/run/dbus/system_bus_socket
        name: dbus-socket
        readOnly: true
      - mountPath: /host/etc/systemd
        name: host-systemd
      - mountPath: /host/oem
        name: host-oem
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5mmtt
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-node-manager
    serviceAccountName: harvester-node-manager
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /sys/kernel/mm/ksm
        type: "null"
      name: ksm
    - hostPath:
        path: /proc
        type: "null"
      name: proc
    - hostPath:
        path: /var/run/dbus/system_bus_socket
        type: "null"
      name: dbus-socket
    - hostPath:
        path: /etc/systemd
        type: "null"
      name: host-systemd
    - hostPath:
        path: /oem
        type: "null"
      name: host-oem
    - name: kube-api-access-5mmtt
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:43Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:43Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://63ba9d9d38eea4f4a802a50668ae6915cb30d78e9100abc89dbb0724254c3d3b
      image: docker.io/rancher/harvester-node-manager:v0.2.1
      imageID: sha256:8e1a6a5cff4e304ef53711ca49183f7877417aba9dbdab8da113862d81b195d3
      lastState: {}
      name: node-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:11:42Z"
    hostIP: 10.10.110.71
    phase: Running
    podIP: 10.52.1.9
    podIPs:
    - ip: 10.52.1.9
    qosClass: Burstable
    startTime: "2024-08-06T02:11:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: a33bf2584d2356d8c37b0de1256e166d5a545c7d1cc9d8e31eae1cdad6d20701
      cni.projectcalico.org/podIP: 10.52.0.44/32
      cni.projectcalico.org/podIPs: 10.52.0.44/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.44"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T01:55:39Z"
    generateName: harvester-node-manager-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-node-manager
      controller-revision-hash: 5557649fd7
      name: harvester-node-manager
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:name: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"4d56340c-2162-4d7d-b7cd-99d82280b9ad"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"node-manager"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"HOST_PROC"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODENAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/host/etc/systemd"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/oem"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/sys/kernel/mm/ksm"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/dbus/system_bus_socket"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"dbus-socket"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-oem"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-systemd"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"ksm"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.44"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:42Z"
    name: harvester-node-manager-nqf82
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-node-manager
      uid: 4d56340c-2162-4d7d-b7cd-99d82280b9ad
    resourceVersion: "4924"
    uid: aa3a5401-0e84-446a-8a6d-0cc3cf01c5bf
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev1
    containers:
    - command:
      - harvester-node-manager
      env:
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: HOST_PROC
        value: /host/proc
      image: rancher/harvester-node-manager:v0.2.1
      imagePullPolicy: IfNotPresent
      name: node-manager
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 64Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /sys/kernel/mm/ksm
        name: ksm
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /var/run/dbus/system_bus_socket
        name: dbus-socket
        readOnly: true
      - mountPath: /host/etc/systemd
        name: host-systemd
      - mountPath: /host/oem
        name: host-oem
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tpv58
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-node-manager
    serviceAccountName: harvester-node-manager
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /sys/kernel/mm/ksm
        type: "null"
      name: ksm
    - hostPath:
        path: /proc
        type: "null"
      name: proc
    - hostPath:
        path: /var/run/dbus/system_bus_socket
        type: "null"
      name: dbus-socket
    - hostPath:
        path: /etc/systemd
        type: "null"
      name: host-systemd
    - hostPath:
        path: /oem
        type: "null"
      name: host-oem
    - name: kube-api-access-tpv58
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c4b1817bb796c0150b17afb92a825f1e6203a5d22a93d78488c345f49cef9d05
      image: docker.io/rancher/harvester-node-manager:v0.2.1
      imageID: sha256:8e1a6a5cff4e304ef53711ca49183f7877417aba9dbdab8da113862d81b195d3
      lastState: {}
      name: node-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:55:42Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.44
    podIPs:
    - ip: 10.52.0.44
    qosClass: Burstable
    startTime: "2024-08-06T01:55:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 0afa89ca819ff9ebcdbad4b634d3b9b5e5aa1bb5608cbeedd32e445154dfde91
      cni.projectcalico.org/podIP: 10.52.2.4/32
      cni.projectcalico.org/podIPs: 10.52.2.4/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.2.4"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:13:15Z"
    generateName: harvester-node-manager-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: harvester-node-manager
      controller-revision-hash: 5557649fd7
      name: harvester-node-manager
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:name: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"4d56340c-2162-4d7d-b7cd-99d82280b9ad"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"node-manager"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"HOST_PROC"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODENAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/host/etc/systemd"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/oem"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/sys/kernel/mm/ksm"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/dbus/system_bus_socket"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"dbus-socket"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-oem"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-systemd"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"ksm"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:13:15Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:28Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:28Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.2.4"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:30Z"
    name: harvester-node-manager-pr8ct
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-node-manager
      uid: 4d56340c-2162-4d7d-b7cd-99d82280b9ad
    resourceVersion: "26555"
    uid: cd615fbd-ea9f-42a4-80c4-083755b8a8e1
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev3
    containers:
    - command:
      - harvester-node-manager
      env:
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: HOST_PROC
        value: /host/proc
      image: rancher/harvester-node-manager:v0.2.1
      imagePullPolicy: IfNotPresent
      name: node-manager
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 10m
          memory: 64Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /sys/kernel/mm/ksm
        name: ksm
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /var/run/dbus/system_bus_socket
        name: dbus-socket
        readOnly: true
      - mountPath: /host/etc/systemd
        name: host-systemd
      - mountPath: /host/oem
        name: host-oem
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-prj25
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev3
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-node-manager
    serviceAccountName: harvester-node-manager
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /sys/kernel/mm/ksm
        type: "null"
      name: ksm
    - hostPath:
        path: /proc
        type: "null"
      name: proc
    - hostPath:
        path: /var/run/dbus/system_bus_socket
        type: "null"
      name: dbus-socket
    - hostPath:
        path: /etc/systemd
        type: "null"
      name: host-systemd
    - hostPath:
        path: /oem
        type: "null"
      name: host-oem
    - name: kube-api-access-prj25
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:15Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:30Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:30Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:15Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://da24a4f5d5f11c000a8f98ac230a8471337afd6a2b46c047e3ab44bc61754fba
      image: docker.io/rancher/harvester-node-manager:v0.2.1
      imageID: sha256:8e1a6a5cff4e304ef53711ca49183f7877417aba9dbdab8da113862d81b195d3
      lastState: {}
      name: node-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:13:30Z"
    hostIP: 10.10.110.61
    phase: Running
    podIP: 10.52.2.4
    podIPs:
    - ip: 10.52.2.4
    qosClass: Burstable
    startTime: "2024-08-06T02:13:15Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 518d71284165d317a8e7e918507c9b30cdf73f5293bc4c5df9e415de7343fa9c
      cni.projectcalico.org/podIP: 10.52.1.24/32
      cni.projectcalico.org/podIPs: 10.52.1.24/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.1.24"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:13:11Z"
    generateName: harvester-node-manager-webhook-9cfccc84c-
    labels:
      app.kubernetes.io/name: harvester-node-manager-webhook
      pod-template-hash: 9cfccc84c
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/name: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"88994f66-64d2-4f02-b271-928ab9b426d1"}: {}
        f:spec:
          f:containers:
            k:{"name":"harvester-node-manager-webhook"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"WEBHOOK_SERVER_HTTPS_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:13:11Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:12Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:12Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.1.24"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:13Z"
    name: harvester-node-manager-webhook-9cfccc84c-6txfh
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-node-manager-webhook-9cfccc84c
      uid: 88994f66-64d2-4f02-b271-928ab9b426d1
    resourceVersion: "25858"
    uid: aa6d1bad-8270-4390-a4b9-2ec0e02bf7a3
  spec:
    containers:
    - env:
      - name: WEBHOOK_SERVER_HTTPS_PORT
        value: "8443"
      - name: NAMESPACE
        value: harvester-system
      image: rancher/harvester-node-manager-webhook:v0.2.1
      imagePullPolicy: IfNotPresent
      name: harvester-node-manager-webhook
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c7rtg
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-node-manager-webhook
    serviceAccountName: harvester-node-manager-webhook
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      operator: Exists
    volumes:
    - name: kube-api-access-c7rtg
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:11Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:13Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:13Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://3564dd9621b07e36c2a57a9b2fb3795d099d2771531432c78c4d62ed3fddcb02
      image: docker.io/rancher/harvester-node-manager-webhook:v0.2.1
      imageID: sha256:3dc3bc0ec02b0398ad90e0a169e6a9fbb467fc115c097f41641a725beaa306e9
      lastState: {}
      name: harvester-node-manager-webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:13:12Z"
    hostIP: 10.10.110.71
    phase: Running
    podIP: 10.52.1.24
    podIPs:
    - ip: 10.52.1.24
    qosClass: BestEffort
    startTime: "2024-08-06T02:13:11Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 24492df2db2bf5764af2ece6e234c48c8c7b82cacd79be37732fd430bc1fa7ee
      cni.projectcalico.org/podIP: 10.52.0.36/32
      cni.projectcalico.org/podIPs: 10.52.0.36/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.36"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T01:55:39Z"
    generateName: harvester-node-manager-webhook-9cfccc84c-
    labels:
      app.kubernetes.io/name: harvester-node-manager-webhook
      pod-template-hash: 9cfccc84c
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/name: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"88994f66-64d2-4f02-b271-928ab9b426d1"}: {}
        f:spec:
          f:containers:
            k:{"name":"harvester-node-manager-webhook"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"WEBHOOK_SERVER_HTTPS_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.36"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:42Z"
    name: harvester-node-manager-webhook-9cfccc84c-nzpdp
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-node-manager-webhook-9cfccc84c
      uid: 88994f66-64d2-4f02-b271-928ab9b426d1
    resourceVersion: "4939"
    uid: 42de966a-178e-486e-97d1-1eedd5f54514
  spec:
    containers:
    - env:
      - name: WEBHOOK_SERVER_HTTPS_PORT
        value: "8443"
      - name: NAMESPACE
        value: harvester-system
      image: rancher/harvester-node-manager-webhook:v0.2.1
      imagePullPolicy: IfNotPresent
      name: harvester-node-manager-webhook
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bbxrp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-node-manager-webhook
    serviceAccountName: harvester-node-manager-webhook
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      operator: Exists
    volumes:
    - name: kube-api-access-bbxrp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://ec1685279f54b431909c3d3ec304f425f6400e6c84560682462f9293b7ce26e4
      image: docker.io/rancher/harvester-node-manager-webhook:v0.2.1
      imageID: sha256:3dc3bc0ec02b0398ad90e0a169e6a9fbb467fc115c097f41641a725beaa306e9
      lastState: {}
      name: harvester-node-manager-webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:55:42Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.36
    podIPs:
    - ip: 10.52.0.36
    qosClass: BestEffort
    startTime: "2024-08-06T01:55:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: eb4d8cd1d05476f4f77dafa0fae6a3a07afaeae63320912bac95c4a2034bce2e
      cni.projectcalico.org/podIP: 10.52.0.110/32
      cni.projectcalico.org/podIPs: 10.52.0.110/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.110"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:11:20Z"
    generateName: harvester-node-manager-webhook-9cfccc84c-
    labels:
      app.kubernetes.io/name: harvester-node-manager-webhook
      pod-template-hash: 9cfccc84c
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:20Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/name: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"88994f66-64d2-4f02-b271-928ab9b426d1"}: {}
        f:spec:
          f:containers:
            k:{"name":"harvester-node-manager-webhook"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"WEBHOOK_SERVER_HTTPS_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:11:20Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:20Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.110"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:21Z"
    name: harvester-node-manager-webhook-9cfccc84c-r6brh
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-node-manager-webhook-9cfccc84c
      uid: 88994f66-64d2-4f02-b271-928ab9b426d1
    resourceVersion: "22679"
    uid: 4904a7cc-d219-421a-81ab-85f97f6c2697
  spec:
    containers:
    - env:
      - name: WEBHOOK_SERVER_HTTPS_PORT
        value: "8443"
      - name: NAMESPACE
        value: harvester-system
      image: rancher/harvester-node-manager-webhook:v0.2.1
      imagePullPolicy: IfNotPresent
      name: harvester-node-manager-webhook
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-d6wfj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-node-manager-webhook
    serviceAccountName: harvester-node-manager-webhook
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      operator: Exists
    volumes:
    - name: kube-api-access-d6wfj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:20Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:21Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:21Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:20Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://dbbfee760c4dc96f0608950c422629af41f9d4307cf993e2b52f642debedaf84
      image: docker.io/rancher/harvester-node-manager-webhook:v0.2.1
      imageID: sha256:3dc3bc0ec02b0398ad90e0a169e6a9fbb467fc115c097f41641a725beaa306e9
      lastState: {}
      name: harvester-node-manager-webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:11:21Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.110
    podIPs:
    - ip: 10.52.0.110
    qosClass: BestEffort
    startTime: "2024-08-06T02:11:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: a62871a9aa0f1d5e73f425f312144ea9f06a3799a0125e8d636269ba9ecde3a8
      cni.projectcalico.org/podIP: 10.52.1.15/32
      cni.projectcalico.org/podIPs: 10.52.1.15/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.1.15"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:11:24Z"
    generateName: harvester-pcidevices-controller-
    labels:
      app.kubernetes.io/instance: pcidevices-controller
      app.kubernetes.io/name: harvester-pcidevices-controller
      controller-revision-hash: 566798679d
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"a653ca27-17aa-4729-8772-a63f70c663f4"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"agent"}:
              .: {}
              f:args: {}
              f:env:
                .: {}
                k:{"name":"GHW_DISABLE_WARNINGS"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/usr/bin/file"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/host/usr/lib"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/lib/modules"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/sys"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/device-plugins"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"device-plugins"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-file"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-lib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"modules"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"sys"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:11:24Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:41Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:41Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.1.15"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:46Z"
    name: harvester-pcidevices-controller-2ndm7
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-pcidevices-controller
      uid: a653ca27-17aa-4729-8772-a63f70c663f4
    resourceVersion: "23628"
    uid: ad2af0f4-fd3e-4f78-be29-3e64b9026924
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev2
    containers:
    - args:
      - agent
      env:
      - name: GHW_DISABLE_WARNINGS
        value: "1"
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: rancher/harvester-pcidevices:v0.3.2
      imagePullPolicy: IfNotPresent
      name: agent
      resources:
        limits:
          cpu: 50m
          memory: 300Mi
        requests:
          cpu: 20m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet/device-plugins
        name: device-plugins
      - mountPath: /lib/modules
        name: modules
      - mountPath: /sys
        name: sys
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/usr/lib
        name: host-lib
      - mountPath: /host/usr/bin/file
        name: host-file
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-r6tfr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev2
    preemptionPolicy: PreemptLowerPriority
    priority: 2.000001e+09
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-pcidevices-controller
    serviceAccountName: harvester-pcidevices-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/kubelet/device-plugins
        type: Directory
      name: device-plugins
    - hostPath:
        path: /lib/modules
        type: Directory
      name: modules
    - hostPath:
        path: /sys
        type: Directory
      name: sys
    - hostPath:
        path: /proc
        type: Directory
      name: proc
    - hostPath:
        path: /usr/lib/
        type: Directory
      name: host-lib
    - hostPath:
        path: /usr/bin/file
        type: File
      name: host-file
    - name: kube-api-access-r6tfr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:46Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:46Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f6b66cb1b1c3124d2db0b8650ac319fe1e5481b32719bed7b1ac8ed8079f5311
      image: docker.io/rancher/harvester-pcidevices:v0.3.2
      imageID: sha256:13527cccde2a14dac969df944799d03458b290da9fa5d4642c95944a08687bf8
      lastState: {}
      name: agent
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:11:45Z"
    hostIP: 10.10.110.71
    phase: Running
    podIP: 10.52.1.15
    podIPs:
    - ip: 10.52.1.15
    qosClass: Burstable
    startTime: "2024-08-06T02:11:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: a81bb83f651851d525319c1406d9e302e36d5b4bcc452ed8079089bf53fcb5e6
      cni.projectcalico.org/podIP: 10.52.3.3/32
      cni.projectcalico.org/podIPs: 10.52.3.3/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.3.3"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:15:35Z"
    generateName: harvester-pcidevices-controller-
    labels:
      app.kubernetes.io/instance: pcidevices-controller
      app.kubernetes.io/name: harvester-pcidevices-controller
      controller-revision-hash: 566798679d
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"a653ca27-17aa-4729-8772-a63f70c663f4"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"agent"}:
              .: {}
              f:args: {}
              f:env:
                .: {}
                k:{"name":"GHW_DISABLE_WARNINGS"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/usr/bin/file"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/host/usr/lib"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/lib/modules"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/sys"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/device-plugins"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"device-plugins"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-file"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-lib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"modules"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"sys"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:15:35Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:15:48Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:15:48Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.3.3"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:15:55Z"
    name: harvester-pcidevices-controller-nsdtz
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-pcidevices-controller
      uid: a653ca27-17aa-4729-8772-a63f70c663f4
    resourceVersion: "30204"
    uid: d7490439-acdc-4146-8b0a-aa9e58c6e948
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev7
    containers:
    - args:
      - agent
      env:
      - name: GHW_DISABLE_WARNINGS
        value: "1"
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: rancher/harvester-pcidevices:v0.3.2
      imagePullPolicy: IfNotPresent
      name: agent
      resources:
        limits:
          cpu: 50m
          memory: 300Mi
        requests:
          cpu: 20m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet/device-plugins
        name: device-plugins
      - mountPath: /lib/modules
        name: modules
      - mountPath: /sys
        name: sys
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/usr/lib
        name: host-lib
      - mountPath: /host/usr/bin/file
        name: host-file
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cdzzp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev7
    preemptionPolicy: PreemptLowerPriority
    priority: 2.000001e+09
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-pcidevices-controller
    serviceAccountName: harvester-pcidevices-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/kubelet/device-plugins
        type: Directory
      name: device-plugins
    - hostPath:
        path: /lib/modules
        type: Directory
      name: modules
    - hostPath:
        path: /sys
        type: Directory
      name: sys
    - hostPath:
        path: /proc
        type: Directory
      name: proc
    - hostPath:
        path: /usr/lib/
        type: Directory
      name: host-lib
    - hostPath:
        path: /usr/bin/file
        type: File
      name: host-file
    - name: kube-api-access-cdzzp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:35Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:55Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:55Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:35Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://50fbd04abdcc0a05431db2b8940ad8b88232eac7abf6b54d23d6931a02c1af3a
      image: docker.io/rancher/harvester-pcidevices:v0.3.2
      imageID: sha256:13527cccde2a14dac969df944799d03458b290da9fa5d4642c95944a08687bf8
      lastState: {}
      name: agent
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:15:54Z"
    hostIP: 10.10.110.232
    phase: Running
    podIP: 10.52.3.3
    podIPs:
    - ip: 10.52.3.3
    qosClass: Burstable
    startTime: "2024-08-06T02:15:35Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 73fae323ed4fce5eb6592c1c8dd1ab171d46947bff847bcfa844dfe56cc681c4
      cni.projectcalico.org/podIP: 10.52.2.9/32
      cni.projectcalico.org/podIPs: 10.52.2.9/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.2.9"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:13:16Z"
    generateName: harvester-pcidevices-controller-
    labels:
      app.kubernetes.io/instance: pcidevices-controller
      app.kubernetes.io/name: harvester-pcidevices-controller
      controller-revision-hash: 566798679d
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"a653ca27-17aa-4729-8772-a63f70c663f4"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"agent"}:
              .: {}
              f:args: {}
              f:env:
                .: {}
                k:{"name":"GHW_DISABLE_WARNINGS"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/usr/bin/file"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/host/usr/lib"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/lib/modules"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/sys"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/device-plugins"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"device-plugins"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-file"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-lib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"modules"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"sys"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:13:16Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:31Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:31Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.2.9"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:35Z"
    name: harvester-pcidevices-controller-sc7dr
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-pcidevices-controller
      uid: a653ca27-17aa-4729-8772-a63f70c663f4
    resourceVersion: "26773"
    uid: 899940d0-33f9-45ca-aebf-9c3c38ee0528
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev3
    containers:
    - args:
      - agent
      env:
      - name: GHW_DISABLE_WARNINGS
        value: "1"
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: rancher/harvester-pcidevices:v0.3.2
      imagePullPolicy: IfNotPresent
      name: agent
      resources:
        limits:
          cpu: 50m
          memory: 300Mi
        requests:
          cpu: 20m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet/device-plugins
        name: device-plugins
      - mountPath: /lib/modules
        name: modules
      - mountPath: /sys
        name: sys
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/usr/lib
        name: host-lib
      - mountPath: /host/usr/bin/file
        name: host-file
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fzflp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev3
    preemptionPolicy: PreemptLowerPriority
    priority: 2.000001e+09
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-pcidevices-controller
    serviceAccountName: harvester-pcidevices-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/kubelet/device-plugins
        type: Directory
      name: device-plugins
    - hostPath:
        path: /lib/modules
        type: Directory
      name: modules
    - hostPath:
        path: /sys
        type: Directory
      name: sys
    - hostPath:
        path: /proc
        type: Directory
      name: proc
    - hostPath:
        path: /usr/lib/
        type: Directory
      name: host-lib
    - hostPath:
        path: /usr/bin/file
        type: File
      name: host-file
    - name: kube-api-access-fzflp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:16Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:35Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:35Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:16Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://5bac91429ad0bc5537d61418bcd40e2f1a95153fd9769c7e90e5598cb619cbeb
      image: docker.io/rancher/harvester-pcidevices:v0.3.2
      imageID: sha256:13527cccde2a14dac969df944799d03458b290da9fa5d4642c95944a08687bf8
      lastState: {}
      name: agent
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:13:35Z"
    hostIP: 10.10.110.61
    phase: Running
    podIP: 10.52.2.9
    podIPs:
    - ip: 10.52.2.9
    qosClass: Burstable
    startTime: "2024-08-06T02:13:16Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: a198fb000a9bb529cd073a7a74631d5c39d24c874de3c38ebbe6c9d4113f448b
      cni.projectcalico.org/podIP: 10.52.0.74/32
      cni.projectcalico.org/podIPs: 10.52.0.74/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.74"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T01:56:42Z"
    generateName: harvester-pcidevices-controller-
    labels:
      app.kubernetes.io/instance: pcidevices-controller
      app.kubernetes.io/name: harvester-pcidevices-controller
      controller-revision-hash: 566798679d
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:42Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"a653ca27-17aa-4729-8772-a63f70c663f4"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"agent"}:
              .: {}
              f:args: {}
              f:env:
                .: {}
                k:{"name":"GHW_DISABLE_WARNINGS"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/host/proc"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host/usr/bin/file"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/host/usr/lib"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/lib/modules"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/sys"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/device-plugins"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"device-plugins"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-file"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-lib"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"modules"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"proc"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"sys"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:56:42Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:42Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.74"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:48Z"
    name: harvester-pcidevices-controller-w77rl
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: harvester-pcidevices-controller
      uid: a653ca27-17aa-4729-8772-a63f70c663f4
    resourceVersion: "7216"
    uid: fc89fabc-29c4-4292-a076-275634293a0e
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev1
    containers:
    - args:
      - agent
      env:
      - name: GHW_DISABLE_WARNINGS
        value: "1"
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: rancher/harvester-pcidevices:v0.3.2
      imagePullPolicy: IfNotPresent
      name: agent
      resources:
        limits:
          cpu: 50m
          memory: 300Mi
        requests:
          cpu: 20m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubelet/device-plugins
        name: device-plugins
      - mountPath: /lib/modules
        name: modules
      - mountPath: /sys
        name: sys
      - mountPath: /host/proc
        name: proc
      - mountPath: /host/usr/lib
        name: host-lib
      - mountPath: /host/usr/bin/file
        name: host-file
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-t4q7b
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 2.000001e+09
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-pcidevices-controller
    serviceAccountName: harvester-pcidevices-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/kubelet/device-plugins
        type: Directory
      name: device-plugins
    - hostPath:
        path: /lib/modules
        type: Directory
      name: modules
    - hostPath:
        path: /sys
        type: Directory
      name: sys
    - hostPath:
        path: /proc
        type: Directory
      name: proc
    - hostPath:
        path: /usr/lib/
        type: Directory
      name: host-lib
    - hostPath:
        path: /usr/bin/file
        type: File
      name: host-file
    - name: kube-api-access-t4q7b
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:42Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:42Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://e2816547472600d127e8248fa1d3c99ada2ba3df7cc6b3cc9f56df720687d010
      image: docker.io/rancher/harvester-pcidevices:v0.3.2
      imageID: sha256:13527cccde2a14dac969df944799d03458b290da9fa5d4642c95944a08687bf8
      lastState: {}
      name: agent
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:56:47Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.74
    podIPs:
    - ip: 10.52.0.74
    qosClass: Burstable
    startTime: "2024-08-06T01:56:42Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 75bb290f8f57a097d8f495af9f35c98a5915b20e5d5d7bc0d81dda6eed49fd66
      cni.projectcalico.org/podIP: 10.52.0.75/32
      cni.projectcalico.org/podIPs: 10.52.0.75/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.75"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T01:56:42Z"
    generateName: harvester-seeder-846c6ff8b4-
    labels:
      app.kubernetes.io/instance: harvester-seeder
      app.kubernetes.io/name: harvester-seeder
      pod-template-hash: 846c6ff8b4
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:42Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"21b2f0e6-bf22-49e5-8585-209ee4e4c244"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
            f:podAntiAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-seeder"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"LEADER_ELECTION_NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"SEEDER_EMBEDDED_MODE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":8080,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":8081,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":9443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:56:42Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:42Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.75"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:45Z"
    name: harvester-seeder-846c6ff8b4-n28lg
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-seeder-846c6ff8b4
      uid: 21b2f0e6-bf22-49e5-8585-209ee4e4c244
    resourceVersion: "7137"
    uid: 5812ef51-c61c-499a-85d8-d612c5c7ad02
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: In
              values:
              - linux
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - seeder
          topologyKey: kubernetes.io/hostname
    containers:
    - env:
      - name: SEEDER_EMBEDDED_MODE
        value: "true"
      - name: LEADER_ELECTION_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/harvester-seeder:v0.3.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /metrics
          port: http
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: harvester-seeder
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      - containerPort: 8081
        name: probe
        protocol: TCP
      - containerPort: 9443
        name: leader
        protocol: TCP
      - containerPort: 443
        name: webhook
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /metrics
          port: http
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: 500m
          memory: 500Mi
        requests:
          cpu: 250m
          memory: 250Mi
      securityContext: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-75xkn
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester-seeder
    serviceAccountName: harvester-seeder
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-75xkn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:42Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:42Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://cf546e72c9bd97e390a73b27c39c3bb96927da0a39feb25517339a0a34fc5dab
      image: docker.io/rancher/harvester-seeder:v0.3.0
      imageID: sha256:e321b05a5cedb1b46ac50c062079ba672769c0c8fe23eb3d16eced9a559a48f8
      lastState: {}
      name: harvester-seeder
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:56:43Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.75
    podIPs:
    - ip: 10.52.0.75
    qosClass: Burstable
    startTime: "2024-08-06T01:56:42Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 80fcafb2d1ced615d96c9c78e54ec96a2e5dfc1d0784daf6c1f091590ab29733
      cni.projectcalico.org/podIP: 10.52.2.6/32
      cni.projectcalico.org/podIPs: 10.52.2.6/32
      container.apparmor.security.beta.kubernetes.io/harvester-webhook: unconfined
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.2.6"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:13:11Z"
    generateName: harvester-webhook-bf9659678-
    labels:
      app.kubernetes.io/component: webhook-server
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: harvester
      app.kubernetes.io/part-of: harvester
      app.kubernetes.io/version: v1.3.1
      helm.sh/chart: harvester-1.3.1
      helm.sh/release: harvester
      pod-template-hash: bf9659678
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:container.apparmor.security.beta.kubernetes.io/harvester-webhook: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/name: {}
            f:app.kubernetes.io/part-of: {}
            f:app.kubernetes.io/version: {}
            f:helm.sh/chart: {}
            f:helm.sh/release: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"1be0858d-181e-49aa-9f72-b9dc6063f0c7"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
            f:podAntiAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-webhook"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"HARVESTER_CONTROLLER_USER_NAME"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_DEBUG"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_WEBHOOK_SERVER_HTTPS_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":9443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:capabilities:
                  .: {}
                  f:add: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:13:11Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
      manager: kube-scheduler
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:11Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:30Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:30Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.2.6"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:31Z"
    name: harvester-webhook-bf9659678-ffl84
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-webhook-bf9659678
      uid: 1be0858d-181e-49aa-9f72-b9dc6063f0c7
    resourceVersion: "26599"
    uid: 8311df6c-ec03-4db5-93c1-7687973a6087
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: In
              values:
              - linux
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - harvester
            - key: app.kubernetes.io/component
              operator: In
              values:
              - webhook-server
            - key: app.kubernetes.io/version
              operator: In
              values:
              - v1.3.1
          topologyKey: kubernetes.io/hostname
    containers:
    - env:
      - name: HARVESTER_WEBHOOK_SERVER_HTTPS_PORT
        value: "9443"
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: HARVESTER_DEBUG
        value: "false"
      - name: HARVESTER_CONTROLLER_USER_NAME
        value: system:serviceaccount:harvester-system:harvester
      image: rancher/harvester-webhook:v1.3.1
      imagePullPolicy: IfNotPresent
      name: harvester-webhook
      ports:
      - containerPort: 9443
        name: https
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          add:
          - SYS_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-b8srv
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev3
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester
    serviceAccountName: harvester
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-b8srv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:15Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:31Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:31Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:15Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://cf8e9fbb11462e638feb61a09c412c0f05b44b40634a903af9404d0c1a9a9032
      image: docker.io/rancher/harvester-webhook:v1.3.1
      imageID: sha256:bedd7044b5b4bee76288c61bd48bc7d7a5f44e3b3891d5373b65023691c21719
      lastState: {}
      name: harvester-webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:13:30Z"
    hostIP: 10.10.110.61
    phase: Running
    podIP: 10.52.2.6
    podIPs:
    - ip: 10.52.2.6
    qosClass: BestEffort
    startTime: "2024-08-06T02:13:15Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 1563d57472d049d92879b821d4279c58a6c499e514f4b0508c7943fe0d2c6ff7
      cni.projectcalico.org/podIP: 10.52.0.38/32
      cni.projectcalico.org/podIPs: 10.52.0.38/32
      container.apparmor.security.beta.kubernetes.io/harvester-webhook: unconfined
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.38"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T01:55:39Z"
    generateName: harvester-webhook-bf9659678-
    labels:
      app.kubernetes.io/component: webhook-server
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: harvester
      app.kubernetes.io/part-of: harvester
      app.kubernetes.io/version: v1.3.1
      helm.sh/chart: harvester-1.3.1
      helm.sh/release: harvester
      pod-template-hash: bf9659678
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:container.apparmor.security.beta.kubernetes.io/harvester-webhook: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/name: {}
            f:app.kubernetes.io/part-of: {}
            f:app.kubernetes.io/version: {}
            f:helm.sh/chart: {}
            f:helm.sh/release: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"1be0858d-181e-49aa-9f72-b9dc6063f0c7"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
            f:podAntiAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-webhook"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"HARVESTER_CONTROLLER_USER_NAME"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_DEBUG"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_WEBHOOK_SERVER_HTTPS_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":9443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:capabilities:
                  .: {}
                  f:add: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.38"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:41Z"
    name: harvester-webhook-bf9659678-flq5s
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-webhook-bf9659678
      uid: 1be0858d-181e-49aa-9f72-b9dc6063f0c7
    resourceVersion: "4870"
    uid: 6cf4ec8b-8074-4fea-aeb9-9797f4f904a2
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: In
              values:
              - linux
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - harvester
            - key: app.kubernetes.io/component
              operator: In
              values:
              - webhook-server
            - key: app.kubernetes.io/version
              operator: In
              values:
              - v1.3.1
          topologyKey: kubernetes.io/hostname
    containers:
    - env:
      - name: HARVESTER_WEBHOOK_SERVER_HTTPS_PORT
        value: "9443"
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: HARVESTER_DEBUG
        value: "false"
      - name: HARVESTER_CONTROLLER_USER_NAME
        value: system:serviceaccount:harvester-system:harvester
      image: rancher/harvester-webhook:v1.3.1
      imagePullPolicy: IfNotPresent
      name: harvester-webhook
      ports:
      - containerPort: 9443
        name: https
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          add:
          - SYS_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hn2hv
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester
    serviceAccountName: harvester
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-hn2hv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:41Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:41Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://16185629b25ad6106bf95413892e40b5e115ff8a05bf1c5665532bcc9670063e
      image: docker.io/rancher/harvester-webhook:v1.3.1
      imageID: sha256:bedd7044b5b4bee76288c61bd48bc7d7a5f44e3b3891d5373b65023691c21719
      lastState: {}
      name: harvester-webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:55:41Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.38
    podIPs:
    - ip: 10.52.0.38
    qosClass: BestEffort
    startTime: "2024-08-06T01:55:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 192b23c50b6940125c7a3fbdd83d4690643e530df6a6c03f4820b65f16067038
      cni.projectcalico.org/podIP: 10.52.1.13/32
      cni.projectcalico.org/podIPs: 10.52.1.13/32
      container.apparmor.security.beta.kubernetes.io/harvester-webhook: unconfined
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.1.13"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T02:11:20Z"
    generateName: harvester-webhook-bf9659678-
    labels:
      app.kubernetes.io/component: webhook-server
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: harvester
      app.kubernetes.io/part-of: harvester
      app.kubernetes.io/version: v1.3.1
      helm.sh/chart: harvester-1.3.1
      helm.sh/release: harvester
      pod-template-hash: bf9659678
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:container.apparmor.security.beta.kubernetes.io/harvester-webhook: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/name: {}
            f:app.kubernetes.io/part-of: {}
            f:app.kubernetes.io/version: {}
            f:helm.sh/chart: {}
            f:helm.sh/release: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"1be0858d-181e-49aa-9f72-b9dc6063f0c7"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
            f:podAntiAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"harvester-webhook"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"HARVESTER_CONTROLLER_USER_NAME"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_DEBUG"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HARVESTER_WEBHOOK_SERVER_HTTPS_PORT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":9443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:capabilities:
                  .: {}
                  f:add: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:11:20Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
      manager: kube-scheduler
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:20Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:41Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:41Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.1.13"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:43Z"
    name: harvester-webhook-bf9659678-mlchh
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: harvester-webhook-bf9659678
      uid: 1be0858d-181e-49aa-9f72-b9dc6063f0c7
    resourceVersion: "23534"
    uid: 7be412ee-db29-43b2-b3f9-d36c5fb37f9a
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: In
              values:
              - linux
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - harvester
            - key: app.kubernetes.io/component
              operator: In
              values:
              - webhook-server
            - key: app.kubernetes.io/version
              operator: In
              values:
              - v1.3.1
          topologyKey: kubernetes.io/hostname
    containers:
    - env:
      - name: HARVESTER_WEBHOOK_SERVER_HTTPS_PORT
        value: "9443"
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: HARVESTER_DEBUG
        value: "false"
      - name: HARVESTER_CONTROLLER_USER_NAME
        value: system:serviceaccount:harvester-system:harvester
      image: rancher/harvester-webhook:v1.3.1
      imagePullPolicy: IfNotPresent
      name: harvester-webhook
      ports:
      - containerPort: 9443
        name: https
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          add:
          - SYS_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-nsvgz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester
    serviceAccountName: harvester
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-nsvgz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:43Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:43Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://2b3fe86a0b8a854a1cd2b30c0fb0d8c22f59879b12b75df74d98081f4c4307ab
      image: docker.io/rancher/harvester-webhook:v1.3.1
      imageID: sha256:bedd7044b5b4bee76288c61bd48bc7d7a5f44e3b3891d5373b65023691c21719
      lastState: {}
      name: harvester-webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:11:42Z"
    hostIP: 10.10.110.71
    phase: Running
    podIP: 10.52.1.13
    podIPs:
    - ip: 10.52.1.13
    qosClass: BestEffort
    startTime: "2024-08-06T02:11:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 6e4120ff92e01c3edcf15dea5ac43b517f595c36fc67500260cdde6575b4138e
      cni.projectcalico.org/podIP: "null"
      cni.projectcalico.org/podIPs: "null"
      helmcharts.helm.cattle.io/configHash: SHA256=66E77741514C98875E32C6961AD72440CDD25971DF2F5E7708537CDDA1297903
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.3.19"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T11:55:29Z"
    generateName: helm-install-harvester-seeder-
    labels:
      batch.kubernetes.io/controller-uid: f575b3d6-7578-4fd8-b403-401990e86f21
      batch.kubernetes.io/job-name: helm-install-harvester-seeder
      controller-uid: f575b3d6-7578-4fd8-b403-401990e86f21
      helmcharts.helm.cattle.io/chart: harvester-seeder
      job-name: helm-install-harvester-seeder
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:helmcharts.helm.cattle.io/configHash: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:batch.kubernetes.io/controller-uid: {}
            f:batch.kubernetes.io/job-name: {}
            f:controller-uid: {}
            f:helmcharts.helm.cattle.io/chart: {}
            f:job-name: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"f575b3d6-7578-4fd8-b403-401990e86f21"}: {}
        f:spec:
          f:containers:
            k:{"name":"helm"}:
              .: {}
              f:args: {}
              f:env:
                .: {}
                k:{"name":"AUTH_PASS_CREDENTIALS"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"CHART"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"CHART_NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"FAILURE_POLICY"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HELM_DRIVER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HELM_VERSION"}:
                  .: {}
                  f:name: {}
                k:{"name":"NAME"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NO_PROXY"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"REPO"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"TARGET_NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"VERSION"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:allowPrivilegeEscalation: {}
                f:capabilities:
                  .: {}
                  f:drop: {}
                f:readOnlyRootFilesystem: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/chart"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/home/klipper-helm/.cache"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/home/klipper-helm/.config"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/home/klipper-helm/.helm"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/tmp"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:nodeSelector: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext:
            .: {}
            f:runAsNonRoot: {}
            f:seccompProfile:
              .: {}
              f:type: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:volumes:
            .: {}
            k:{"name":"content"}:
              .: {}
              f:configMap:
                .: {}
                f:defaultMode: {}
                f:name: {}
              f:name: {}
            k:{"name":"klipper-cache"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"klipper-config"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"klipper-helm"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"tmp"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"values"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:secretName: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T11:55:29Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T11:55:29Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T11:55:36Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.3.19"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T11:55:36Z"
    name: helm-install-harvester-seeder-cxdr4
    namespace: harvester-system
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: helm-install-harvester-seeder
      uid: f575b3d6-7578-4fd8-b403-401990e86f21
    resourceVersion: "630336"
    uid: f7b18c02-34df-4970-96da-a9fd11497ad9
  spec:
    containers:
    - args:
      - install
      - --version
      - 0.3.0
      env:
      - name: NAME
        value: harvester-seeder
      - name: VERSION
        value: 0.3.0
      - name: REPO
        value: http://harvester-cluster-repo.cattle-system.svc/charts
      - name: HELM_DRIVER
        value: secret
      - name: CHART_NAMESPACE
        value: harvester-system
      - name: CHART
        value: harvester-seeder/harvester-seeder
      - name: HELM_VERSION
      - name: TARGET_NAMESPACE
        value: harvester-system
      - name: AUTH_PASS_CREDENTIALS
        value: "false"
      - name: NO_PROXY
        value: .svc,.cluster.local,10.52.0.0/16,10.53.0.0/16
      - name: FAILURE_POLICY
        value: reinstall
      image: rancher/klipper-helm:v0.8.3-build20240228
      imagePullPolicy: IfNotPresent
      name: helm
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /home/klipper-helm/.helm
        name: klipper-helm
      - mountPath: /home/klipper-helm/.cache
        name: klipper-cache
      - mountPath: /home/klipper-helm/.config
        name: klipper-config
      - mountPath: /tmp
        name: tmp
      - mountPath: /config
        name: values
      - mountPath: /chart
        name: content
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-qjkj9
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev7
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: helm-harvester-seeder
    serviceAccountName: helm-harvester-seeder
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir:
        medium: Memory
      name: klipper-helm
    - emptyDir:
        medium: Memory
      name: klipper-cache
    - emptyDir:
        medium: Memory
      name: klipper-config
    - emptyDir:
        medium: Memory
      name: tmp
    - name: values
      secret:
        defaultMode: 420
        secretName: chart-values-harvester-seeder
    - configMap:
        defaultMode: 420
        name: chart-content-harvester-seeder
      name: content
    - name: kube-api-access-qjkj9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:29Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:34Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:34Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://27b76078180eea743e9c21d808ba53472da0605b5b86760370c0192f1b022e29
      image: docker.io/rancher/klipper-helm:v0.8.3-build20240228
      imageID: sha256:0929b4140ada6f9e22dcbd50b15225babc4bc99822a237de438fdcf77ea26821
      lastState: {}
      name: helm
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://27b76078180eea743e9c21d808ba53472da0605b5b86760370c0192f1b022e29
          exitCode: 0
          finishedAt: "2024-08-06T11:55:34Z"
          message: |
            Upgrading helm_v3 chart
          reason: Completed
          startedAt: "2024-08-06T11:55:31Z"
    hostIP: 10.10.110.232
    phase: Succeeded
    podIP: 10.52.3.19
    podIPs:
    - ip: 10.52.3.19
    qosClass: BestEffort
    startTime: "2024-08-06T11:55:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: c91117432e65220330f54fc073ecea50b59fda457f8dc4a4258df5dfc0b805ab
      cni.projectcalico.org/podIP: "null"
      cni.projectcalico.org/podIPs: "null"
      helmcharts.helm.cattle.io/configHash: SHA256=CB09AE079AEFF8FA08D61060DB0542F34505AC1398BF136D7C86BCCB8773D4AC
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.3.16"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T11:55:28Z"
    generateName: helm-install-nvidia-driver-toolkit-
    labels:
      batch.kubernetes.io/controller-uid: 8b1cf558-810c-499d-8a45-bc01fa7059fe
      batch.kubernetes.io/job-name: helm-install-nvidia-driver-toolkit
      controller-uid: 8b1cf558-810c-499d-8a45-bc01fa7059fe
      helmcharts.helm.cattle.io/chart: nvidia-driver-toolkit
      job-name: helm-install-nvidia-driver-toolkit
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:helmcharts.helm.cattle.io/configHash: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:batch.kubernetes.io/controller-uid: {}
            f:batch.kubernetes.io/job-name: {}
            f:controller-uid: {}
            f:helmcharts.helm.cattle.io/chart: {}
            f:job-name: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"8b1cf558-810c-499d-8a45-bc01fa7059fe"}: {}
        f:spec:
          f:containers:
            k:{"name":"helm"}:
              .: {}
              f:args: {}
              f:env:
                .: {}
                k:{"name":"AUTH_PASS_CREDENTIALS"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"CHART"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"CHART_NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"FAILURE_POLICY"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HELM_DRIVER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HELM_VERSION"}:
                  .: {}
                  f:name: {}
                k:{"name":"NAME"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NO_PROXY"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"REPO"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"TARGET_NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"VERSION"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:allowPrivilegeEscalation: {}
                f:capabilities:
                  .: {}
                  f:drop: {}
                f:readOnlyRootFilesystem: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/chart"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/home/klipper-helm/.cache"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/home/klipper-helm/.config"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/home/klipper-helm/.helm"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/tmp"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:nodeSelector: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext:
            .: {}
            f:runAsNonRoot: {}
            f:seccompProfile:
              .: {}
              f:type: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:volumes:
            .: {}
            k:{"name":"content"}:
              .: {}
              f:configMap:
                .: {}
                f:defaultMode: {}
                f:name: {}
              f:name: {}
            k:{"name":"klipper-cache"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"klipper-config"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"klipper-helm"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"tmp"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"values"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:secretName: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T11:55:28Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T11:55:29Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T11:55:35Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.3.16"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T11:55:35Z"
    name: helm-install-nvidia-driver-toolkit-mw2t8
    namespace: harvester-system
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: helm-install-nvidia-driver-toolkit
      uid: 8b1cf558-810c-499d-8a45-bc01fa7059fe
    resourceVersion: "630316"
    uid: 5157e323-d21b-413c-8a06-b33a12db688c
  spec:
    containers:
    - args:
      - install
      - --version
      - 0.1.1
      env:
      - name: NAME
        value: nvidia-driver-toolkit
      - name: VERSION
        value: 0.1.1
      - name: REPO
        value: http://harvester-cluster-repo.cattle-system.svc/charts
      - name: HELM_DRIVER
        value: secret
      - name: CHART_NAMESPACE
        value: harvester-system
      - name: CHART
        value: nvidia-driver-toolkit/nvidia-driver-runtime
      - name: HELM_VERSION
      - name: TARGET_NAMESPACE
        value: harvester-system
      - name: AUTH_PASS_CREDENTIALS
        value: "false"
      - name: NO_PROXY
        value: .svc,.cluster.local,10.52.0.0/16,10.53.0.0/16
      - name: FAILURE_POLICY
        value: reinstall
      image: rancher/klipper-helm:v0.8.3-build20240228
      imagePullPolicy: IfNotPresent
      name: helm
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /home/klipper-helm/.helm
        name: klipper-helm
      - mountPath: /home/klipper-helm/.cache
        name: klipper-cache
      - mountPath: /home/klipper-helm/.config
        name: klipper-config
      - mountPath: /tmp
        name: tmp
      - mountPath: /config
        name: values
      - mountPath: /chart
        name: content
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-wqsfr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev7
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: helm-nvidia-driver-toolkit
    serviceAccountName: helm-nvidia-driver-toolkit
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir:
        medium: Memory
      name: klipper-helm
    - emptyDir:
        medium: Memory
      name: klipper-cache
    - emptyDir:
        medium: Memory
      name: klipper-config
    - emptyDir:
        medium: Memory
      name: tmp
    - name: values
      secret:
        defaultMode: 420
        secretName: chart-values-nvidia-driver-toolkit
    - configMap:
        defaultMode: 420
        name: chart-content-nvidia-driver-toolkit
      name: content
    - name: kube-api-access-wqsfr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:28Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:33Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:33Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:28Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://84bf1783c22fd5523e742a9cd1de585a0ca405ba193a416a73bd0cda763b3d76
      image: docker.io/rancher/klipper-helm:v0.8.3-build20240228
      imageID: sha256:0929b4140ada6f9e22dcbd50b15225babc4bc99822a237de438fdcf77ea26821
      lastState: {}
      name: helm
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://84bf1783c22fd5523e742a9cd1de585a0ca405ba193a416a73bd0cda763b3d76
          exitCode: 0
          finishedAt: "2024-08-06T11:55:32Z"
          message: |
            Upgrading helm_v3 chart
          reason: Completed
          startedAt: "2024-08-06T11:55:31Z"
    hostIP: 10.10.110.232
    phase: Succeeded
    podIP: 10.52.3.16
    podIPs:
    - ip: 10.52.3.16
    qosClass: BestEffort
    startTime: "2024-08-06T11:55:28Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 7f9fa7094c50e70a9018b1ab74276475ea8b226e2ebc5ebbbb64d4035c32070c
      cni.projectcalico.org/podIP: "null"
      cni.projectcalico.org/podIPs: "null"
      helmcharts.helm.cattle.io/configHash: SHA256=D8ED676F7EC1B0D179CAE308D7A067307CD86E00F0AA2B316DFA2024BB27233F
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.3.18"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T11:55:29Z"
    generateName: helm-install-pcidevices-controller-
    labels:
      batch.kubernetes.io/controller-uid: 2b474489-3d36-4ac6-b645-751b9613dce6
      batch.kubernetes.io/job-name: helm-install-pcidevices-controller
      controller-uid: 2b474489-3d36-4ac6-b645-751b9613dce6
      helmcharts.helm.cattle.io/chart: pcidevices-controller
      job-name: helm-install-pcidevices-controller
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:helmcharts.helm.cattle.io/configHash: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:batch.kubernetes.io/controller-uid: {}
            f:batch.kubernetes.io/job-name: {}
            f:controller-uid: {}
            f:helmcharts.helm.cattle.io/chart: {}
            f:job-name: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"2b474489-3d36-4ac6-b645-751b9613dce6"}: {}
        f:spec:
          f:containers:
            k:{"name":"helm"}:
              .: {}
              f:args: {}
              f:env:
                .: {}
                k:{"name":"AUTH_PASS_CREDENTIALS"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"CHART"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"CHART_NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"FAILURE_POLICY"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HELM_DRIVER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"HELM_VERSION"}:
                  .: {}
                  f:name: {}
                k:{"name":"NAME"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NO_PROXY"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"REPO"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"TARGET_NAMESPACE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"VERSION"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:allowPrivilegeEscalation: {}
                f:capabilities:
                  .: {}
                  f:drop: {}
                f:readOnlyRootFilesystem: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/chart"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/config"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/home/klipper-helm/.cache"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/home/klipper-helm/.config"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/home/klipper-helm/.helm"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/tmp"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:nodeSelector: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext:
            .: {}
            f:runAsNonRoot: {}
            f:seccompProfile:
              .: {}
              f:type: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:volumes:
            .: {}
            k:{"name":"content"}:
              .: {}
              f:configMap:
                .: {}
                f:defaultMode: {}
                f:name: {}
              f:name: {}
            k:{"name":"klipper-cache"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"klipper-config"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"klipper-helm"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"tmp"}:
              .: {}
              f:emptyDir:
                .: {}
                f:medium: {}
              f:name: {}
            k:{"name":"values"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:secretName: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T11:55:29Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T11:55:29Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T11:55:35Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:reason: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.3.18"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T11:55:35Z"
    name: helm-install-pcidevices-controller-jbr27
    namespace: harvester-system
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: helm-install-pcidevices-controller
      uid: 2b474489-3d36-4ac6-b645-751b9613dce6
    resourceVersion: "630319"
    uid: 9eacb989-f679-492b-82f8-a08d1abd32ef
  spec:
    containers:
    - args:
      - install
      - --version
      - 0.3.2
      env:
      - name: NAME
        value: pcidevices-controller
      - name: VERSION
        value: 0.3.2
      - name: REPO
        value: http://harvester-cluster-repo.cattle-system.svc/charts
      - name: HELM_DRIVER
        value: secret
      - name: CHART_NAMESPACE
        value: harvester-system
      - name: CHART
        value: pcidevices-controller/harvester-pcidevices-controller
      - name: HELM_VERSION
      - name: TARGET_NAMESPACE
        value: harvester-system
      - name: AUTH_PASS_CREDENTIALS
        value: "false"
      - name: NO_PROXY
        value: .svc,.cluster.local,10.52.0.0/16,10.53.0.0/16
      - name: FAILURE_POLICY
        value: reinstall
      image: rancher/klipper-helm:v0.8.3-build20240228
      imagePullPolicy: IfNotPresent
      name: helm
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /home/klipper-helm/.helm
        name: klipper-helm
      - mountPath: /home/klipper-helm/.cache
        name: klipper-cache
      - mountPath: /home/klipper-helm/.config
        name: klipper-config
      - mountPath: /tmp
        name: tmp
      - mountPath: /config
        name: values
      - mountPath: /chart
        name: content
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c5l2r
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev7
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: helm-pcidevices-controller
    serviceAccountName: helm-pcidevices-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir:
        medium: Memory
      name: klipper-helm
    - emptyDir:
        medium: Memory
      name: klipper-cache
    - emptyDir:
        medium: Memory
      name: klipper-config
    - emptyDir:
        medium: Memory
      name: tmp
    - name: values
      secret:
        defaultMode: 420
        secretName: chart-values-pcidevices-controller
    - configMap:
        defaultMode: 420
        name: chart-content-pcidevices-controller
      name: content
    - name: kube-api-access-c5l2r
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:29Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:33Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:33Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T11:55:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://e48a6c6f9b9d2ec3a2103ad01408bed3f42dde65bc85b330f96783ff85c84cc1
      image: docker.io/rancher/klipper-helm:v0.8.3-build20240228
      imageID: sha256:0929b4140ada6f9e22dcbd50b15225babc4bc99822a237de438fdcf77ea26821
      lastState: {}
      name: helm
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://e48a6c6f9b9d2ec3a2103ad01408bed3f42dde65bc85b330f96783ff85c84cc1
          exitCode: 0
          finishedAt: "2024-08-06T11:55:33Z"
          message: |
            Upgrading helm_v3 chart
          reason: Completed
          startedAt: "2024-08-06T11:55:31Z"
    hostIP: 10.10.110.232
    phase: Succeeded
    podIP: 10.52.3.18
    podIPs:
    - ip: 10.52.3.18
    qosClass: BestEffort
    startTime: "2024-08-06T11:55:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-06T01:55:39Z"
    generateName: kube-vip-
    labels:
      app.kubernetes.io/instance: harvester
      app.kubernetes.io/name: kube-vip
      controller-revision-hash: 6cc75d79b8
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"6a5a5386-27f4-4abb-a4ab-fb71fe92b78d"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"kube-vip"}:
              .: {}
              f:args: {}
              f:env:
                .: {}
                k:{"name":"cp_enable"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"enable_service_security"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"lb_enable"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"lb_port"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"svc_enable"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"vip_arp"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"vip_cidr"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"vip_interface"}:
                  .: {}
                  f:name: {}
                k:{"name":"vip_leaderelection"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:capabilities:
                  .: {}
                  f:add: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:nodeSelector: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.10.110.11"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:41Z"
    name: kube-vip-tswcs
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-vip
      uid: 6a5a5386-27f4-4abb-a4ab-fb71fe92b78d
    resourceVersion: "4879"
    uid: 649286c0-814a-4a1f-bbc5-28ad326c0b47
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev1
    containers:
    - args:
      - manager
      env:
      - name: cp_enable
        value: "false"
      - name: enable_service_security
        value: "true"
      - name: lb_enable
        value: "true"
      - name: lb_port
        value: "6443"
      - name: svc_enable
        value: "true"
      - name: vip_arp
        value: "true"
      - name: vip_cidr
        value: "32"
      - name: vip_interface
      - name: vip_leaderelection
        value: "false"
      image: ghcr.io/kube-vip/kube-vip-iptables:v0.6.0
      imagePullPolicy: IfNotPresent
      name: kube-vip
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-f78sr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: harvesterdev1
    nodeSelector:
      node-role.kubernetes.io/control-plane: "true"
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-vip
    serviceAccountName: kube-vip
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: kube-api-access-f78sr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:41Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:41Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://a60401a6c7252006a12ca4469fbb90d5273e245bbb98234e982fe878d4e74d98
      image: ghcr.io/kube-vip/kube-vip-iptables:v0.6.0
      imageID: sha256:636aff9a37178493e1e1bfc129d1915bfa04c620b6e8222c36fd90ab99c5a617
      lastState: {}
      name: kube-vip
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:55:40Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.10.110.11
    podIPs:
    - ip: 10.10.110.11
    qosClass: BestEffort
    startTime: "2024-08-06T01:55:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 2c3f7724814d227415ad846f29348553d34d817db7752b161aa082ac2cf8eed5
      cni.projectcalico.org/podIP: 10.52.3.27/32
      cni.projectcalico.org/podIPs: 10.52.3.27/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.3.27"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T13:47:30Z"
    generateName: nvidia-driver-runtime-
    labels:
      app: nvidia-driver-daemonset
      app.kubernetes.io/instance: nvidia-driver-toolkit
      app.kubernetes.io/name: nvidia-driver-runtime
      controller-revision-hash: 77f5df7f56
      pod-template-generation: "6"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/name: {}
            f:controller-revision-hash: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"cbd0a9b8-1cd8-4272-b4b9-75a617505a71"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"nvidia-driver-ctr"}:
              .: {}
              f:env:
                .: {}
                k:{"name":"DRIVER_LOCATION"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/dev/log"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/host-etc/os-release"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/sys"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/log"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostPID: {}
          f:nodeSelector: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"dev-log"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-os-release"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"host-sys"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"var-log"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T13:47:30Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T13:47:31Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T13:47:31Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.3.27"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T13:47:32Z"
    name: nvidia-driver-runtime-lgzr2
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: nvidia-driver-runtime
      uid: cbd0a9b8-1cd8-4272-b4b9-75a617505a71
    resourceVersion: "744936"
    uid: 6ca27d4d-3161-4a70-ba1d-9295f17b5d68
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev7
    containers:
    - env:
      - name: DRIVER_LOCATION
        value: http://192.168.210.5:8080/vgpu/NVIDIA-Linux-x86_64-535.183.04-vgpu-kvm.run
      image: registry.gitlab.com/koat-public/koat-nvidia-driver-toolkit:latest
      imagePullPolicy: Always
      name: nvidia-driver-ctr
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/log
        name: var-log
      - mountPath: /dev/log
        name: dev-log
      - mountPath: /host-etc/os-release
        name: host-os-release
        readOnly: true
      - mountPath: /sys
        name: host-sys
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bqgzl
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostPID: true
    nodeName: harvesterdev7
    nodeSelector:
      sriovgpu.harvesterhci.io/driver-needed: "true"
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: nvidia-driver-runtime
    serviceAccountName: nvidia-driver-runtime
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/log
        type: "null"
      name: var-log
    - hostPath:
        path: /dev/log
        type: "null"
      name: dev-log
    - hostPath:
        path: /etc/os-release
        type: "null"
      name: host-os-release
    - hostPath:
        path: /sys
        type: Directory
      name: host-sys
    - name: kube-api-access-bqgzl
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T13:47:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T13:47:32Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T13:47:32Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T13:47:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://0f575aacddbb1dfc9cb86b4ad60a579a679c23a7c6d3362ec69d4672e5ecfd5c
      image: registry.gitlab.com/koat-public/koat-nvidia-driver-toolkit:latest
      imageID: registry.gitlab.com/koat-public/koat-nvidia-driver-toolkit@sha256:c92caac0fb4c3e923566c3ab589d77a1b1b8950a690f00f0bcc1460fce4315a9
      lastState: {}
      name: nvidia-driver-ctr
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T13:47:32Z"
    hostIP: 10.10.110.232
    phase: Running
    podIP: 10.52.3.27
    podIPs:
    - ip: 10.52.3.27
    qosClass: BestEffort
    startTime: "2024-08-06T13:47:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 7a8d9c79630c75bdeab4af4dd7f83c6cb9c1c08a15addce143100a3787d0811e
      cni.projectcalico.org/podIP: 10.52.3.28/32
      cni.projectcalico.org/podIPs: 10.52.3.28/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.3.28"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T14:12:10Z"
    generateName: supportbundle-manager-bundle-vuocj-77457f48f7-
    labels:
      app: support-bundle-manager
      pod-template-hash: 77457f48f7
      rancher/supportbundle: bundle-vuocj
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T14:12:10Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app: {}
            f:pod-template-hash: {}
            f:rancher/supportbundle: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"6fb749a2-70f5-41a8-abba-9bdcece60efe"}: {}
        f:spec:
          f:containers:
            k:{"name":"manager"}:
              .: {}
              f:args: {}
              f:env:
                .: {}
                k:{"name":"SUPPORT_BUNDLE_DEBUG"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SUPPORT_BUNDLE_DESCRIPTION"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SUPPORT_BUNDLE_EXCLUDE_RESOURCES"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SUPPORT_BUNDLE_EXTRA_COLLECTORS"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SUPPORT_BUNDLE_IMAGE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SUPPORT_BUNDLE_IMAGE_PULL_POLICY"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SUPPORT_BUNDLE_ISSUE_URL"}:
                  .: {}
                  f:name: {}
                k:{"name":"SUPPORT_BUNDLE_MANAGER_POD_IP"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"SUPPORT_BUNDLE_NAME"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SUPPORT_BUNDLE_NODE_SELECTOR"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SUPPORT_BUNDLE_NODE_TIMEOUT"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SUPPORT_BUNDLE_TAINT_TOLERATION"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SUPPORT_BUNDLE_TARGET_NAMESPACES"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8080,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:protocol: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T14:12:10Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T14:12:10Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.3.28"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T14:12:12Z"
    name: supportbundle-manager-bundle-vuocj-77457f48f7-kcpx7
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: supportbundle-manager-bundle-vuocj-77457f48f7
      uid: 6fb749a2-70f5-41a8-abba-9bdcece60efe
    resourceVersion: "770148"
    uid: e0e91650-e0fb-415d-acb7-2ef63ba6c489
  spec:
    containers:
    - args:
      - /usr/bin/support-bundle-kit
      - manager
      env:
      - name: SUPPORT_BUNDLE_TARGET_NAMESPACES
        value: cattle-dashboards,cattle-fleet-local-system,cattle-fleet-system,cattle-fleet-clusters-system,cattle-monitoring-system,fleet-local,harvester-system,local,longhorn-system,cattle-logging-system
      - name: SUPPORT_BUNDLE_NAME
        value: bundle-vuocj
      - name: SUPPORT_BUNDLE_DESCRIPTION
        value: the gpu vm does not start
      - name: SUPPORT_BUNDLE_ISSUE_URL
      - name: SUPPORT_BUNDLE_DEBUG
        value: "true"
      - name: SUPPORT_BUNDLE_MANAGER_POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: SUPPORT_BUNDLE_IMAGE
        value: rancher/support-bundle-kit:v0.0.38
      - name: SUPPORT_BUNDLE_IMAGE_PULL_POLICY
        value: IfNotPresent
      - name: SUPPORT_BUNDLE_NODE_SELECTOR
        value: harvesterhci.io/managed=true
      - name: SUPPORT_BUNDLE_EXCLUDE_RESOURCES
        value: settings.harvesterhci.io,authconfigs.management.cattle.io,authtokens.management.cattle.io,samltokens.management.cattle.io,tokens.management.cattle.io,users.management.cattle.io
      - name: SUPPORT_BUNDLE_EXTRA_COLLECTORS
        value: harvester
      - name: SUPPORT_BUNDLE_TAINT_TOLERATION
        value: ':'
      - name: SUPPORT_BUNDLE_NODE_TIMEOUT
        value: 30m0s
      image: rancher/support-bundle-kit:v0.0.38
      imagePullPolicy: IfNotPresent
      name: manager
      ports:
      - containerPort: 8080
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-mp8td
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev7
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: harvester
    serviceAccountName: harvester
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-mp8td
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T14:12:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T14:12:12Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T14:12:12Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T14:12:10Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://205e73878f5e6edbc52f8c12bc7b7219b41bbe9b4bce9aa28a5f77c6cac6906b
      image: docker.io/rancher/support-bundle-kit:v0.0.38
      imageID: sha256:385faeb1267eacee0112cc2469761a95cfbe9b6b807e36d5a988479ad39bc4d9
      lastState: {}
      name: manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T14:12:11Z"
    hostIP: 10.10.110.232
    phase: Running
    podIP: 10.52.3.28
    podIPs:
    - ip: 10.52.3.28
    qosClass: BestEffort
    startTime: "2024-08-06T14:12:10Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 091c6445ac4a86a3c31ab8991ea247fb4e0ea5d193411740f019f3e049146d59
      cni.projectcalico.org/podIP: 10.52.0.64/32
      cni.projectcalico.org/podIPs: 10.52.0.64/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.64"
            ],
            "default": true,
            "dns": {}
        }]
      kubevirt.io/install-strategy-identifier: 8c5c8323ebf23c689ce9bc87a13132d3fae18c7a
      kubevirt.io/install-strategy-registry: registry.suse.com/suse/sles/15.5
      kubevirt.io/install-strategy-version: 1.1.1-150500.8.15.1
    creationTimestamp: "2024-08-06T01:56:18Z"
    generateName: virt-api-788c88fb89-
    labels:
      app.kubernetes.io/component: kubevirt
      app.kubernetes.io/managed-by: virt-operator
      app.kubernetes.io/version: 1.1.1-150500.8.15.1
      kubevirt.io: virt-api
      pod-template-hash: 788c88fb89
      prometheus.kubevirt.io: "true"
    name: virt-api-788c88fb89-4qt9b
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: virt-api-788c88fb89
      uid: ce32987b-e000-4d02-982d-25535cf1fb97
    resourceVersion: "6346"
    uid: c2df8c88-acd0-4421-aa05-a1c64df732a1
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: kubevirt.io
                operator: In
                values:
                - virt-api
            topologyKey: kubernetes.io/hostname
          weight: 1
    containers:
    - args:
      - --port
      - "8443"
      - --console-server-port
      - "8186"
      - --subresources-only
      - -v
      - "2"
      command:
      - virt-api
      image: registry.suse.com/suse/sles/15.5/virt-api:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      name: virt-api
      ports:
      - containerPort: 8443
        name: virt-api
        protocol: TCP
      - containerPort: 8443
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /apis/subresources.kubevirt.io/v1/healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: 400m
          memory: 1100Mi
        requests:
          cpu: 5m
          memory: 500Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/virt-api/certificates
        name: kubevirt-virt-api-certs
        readOnly: true
      - mountPath: /etc/virt-handler/clientcertificates
        name: kubevirt-virt-handler-certs
        readOnly: true
      - mountPath: /profile-data
        name: profile-data
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5s488
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 1e+09
    priorityClassName: kubevirt-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kubevirt-apiserver
    serviceAccountName: kubevirt-apiserver
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kubevirt-virt-api-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-api-certs
    - name: kubevirt-virt-handler-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-handler-certs
    - emptyDir: {}
      name: profile-data
    - name: kube-api-access-5s488
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:18Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:38Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:38Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:18Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://5d9c852c34fe591bc7452756495d10eaa26106ad0d694e129a6ba3cd5a5bfa34
      image: registry.suse.com/suse/sles/15.5/virt-api:1.1.1-150500.8.15.1
      imageID: sha256:b91a76181e73bb460ec504a9f52ff440232978f48fd282e2041099d6ca954b26
      lastState: {}
      name: virt-api
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:56:19Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.64
    podIPs:
    - ip: 10.52.0.64
    qosClass: Burstable
    startTime: "2024-08-06T01:56:18Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 77ae1c4488bdd56882c112a3715030e327793405e9fb903f0596d1983f6247a6
      cni.projectcalico.org/podIP: 10.52.1.3/32
      cni.projectcalico.org/podIPs: 10.52.1.3/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.1.3"
            ],
            "default": true,
            "dns": {}
        }]
      kubevirt.io/install-strategy-identifier: 8c5c8323ebf23c689ce9bc87a13132d3fae18c7a
      kubevirt.io/install-strategy-registry: registry.suse.com/suse/sles/15.5
      kubevirt.io/install-strategy-version: 1.1.1-150500.8.15.1
    creationTimestamp: "2024-08-06T02:11:29Z"
    generateName: virt-api-788c88fb89-
    labels:
      app.kubernetes.io/component: kubevirt
      app.kubernetes.io/managed-by: virt-operator
      app.kubernetes.io/version: 1.1.1-150500.8.15.1
      kubevirt.io: virt-api
      pod-template-hash: 788c88fb89
      prometheus.kubevirt.io: "true"
    name: virt-api-788c88fb89-bnbdk
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: virt-api-788c88fb89
      uid: ce32987b-e000-4d02-982d-25535cf1fb97
    resourceVersion: "23795"
    uid: a0a6874b-a2ef-4b58-8ace-72548dd5c23c
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: kubevirt.io
                operator: In
                values:
                - virt-api
            topologyKey: kubernetes.io/hostname
          weight: 1
    containers:
    - args:
      - --port
      - "8443"
      - --console-server-port
      - "8186"
      - --subresources-only
      - -v
      - "2"
      command:
      - virt-api
      image: registry.suse.com/suse/sles/15.5/virt-api:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      name: virt-api
      ports:
      - containerPort: 8443
        name: virt-api
        protocol: TCP
      - containerPort: 8443
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /apis/subresources.kubevirt.io/v1/healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: 400m
          memory: 1100Mi
        requests:
          cpu: 5m
          memory: 500Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/virt-api/certificates
        name: kubevirt-virt-api-certs
        readOnly: true
      - mountPath: /etc/virt-handler/clientcertificates
        name: kubevirt-virt-handler-certs
        readOnly: true
      - mountPath: /profile-data
        name: profile-data
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5ms8s
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev2
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 1e+09
    priorityClassName: kubevirt-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kubevirt-apiserver
    serviceAccountName: kubevirt-apiserver
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kubevirt-virt-api-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-api-certs
    - name: kubevirt-virt-handler-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-handler-certs
    - emptyDir: {}
      name: profile-data
    - name: kube-api-access-5ms8s
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:53Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:53Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://6477ff12fbf38e1bd723316a8577757ca12b0eac73b3b43539172cc2b66f4f81
      image: registry.suse.com/suse/sles/15.5/virt-api:1.1.1-150500.8.15.1
      imageID: sha256:b91a76181e73bb460ec504a9f52ff440232978f48fd282e2041099d6ca954b26
      lastState: {}
      name: virt-api
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:11:31Z"
    hostIP: 10.10.110.71
    phase: Running
    podIP: 10.52.1.3
    podIPs:
    - ip: 10.52.1.3
    qosClass: Burstable
    startTime: "2024-08-06T02:11:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 0e409e915cf7dee8dda6facd2b703ccec35d1245930dbea51d033218bbac372c
      cni.projectcalico.org/podIP: 10.52.0.79/32
      cni.projectcalico.org/podIPs: 10.52.0.79/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.79"
            ],
            "default": true,
            "dns": {}
        }]
      kubevirt.io/install-strategy-identifier: 8c5c8323ebf23c689ce9bc87a13132d3fae18c7a
      kubevirt.io/install-strategy-registry: registry.suse.com/suse/sles/15.5
      kubevirt.io/install-strategy-version: 1.1.1-150500.8.15.1
    creationTimestamp: "2024-08-06T01:56:43Z"
    generateName: virt-controller-656bc79754-
    labels:
      app.kubernetes.io/component: kubevirt
      app.kubernetes.io/managed-by: virt-operator
      app.kubernetes.io/version: 1.1.1-150500.8.15.1
      kubevirt.io: virt-controller
      pod-template-hash: 656bc79754
      prometheus.kubevirt.io: "true"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubevirt.io/install-strategy-identifier: {}
            f:kubevirt.io/install-strategy-registry: {}
            f:kubevirt.io/install-strategy-version: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/version: {}
            f:kubevirt.io: {}
            f:pod-template-hash: {}
            f:prometheus.kubevirt.io: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"8f8ad8a0-cb1d-4a7c-a555-2332e6a59867"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:podAntiAffinity:
              .: {}
              f:preferredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"virt-controller"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:allowPrivilegeEscalation: {}
                f:capabilities:
                  .: {}
                  f:drop: {}
                f:seccompProfile:
                  .: {}
                  f:type: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/virt-controller/certificates"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/etc/virt-controller/exportca"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/profile-data"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext:
            .: {}
            f:runAsNonRoot: {}
            f:seccompProfile:
              .: {}
              f:type: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"kubevirt-controller-certs"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"kubevirt-export-ca"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"profile-data"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:56:43Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:44Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:44Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.79"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:57:03Z"
    name: virt-controller-656bc79754-54t2c
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: virt-controller-656bc79754
      uid: 8f8ad8a0-cb1d-4a7c-a555-2332e6a59867
    resourceVersion: "8064"
    uid: 13867174-5740-4c3d-a070-59cccf8ced2d
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: kubevirt.io
                operator: In
                values:
                - virt-controller
            topologyKey: kubernetes.io/hostname
          weight: 1
    containers:
    - args:
      - --launcher-image
      - registry.suse.com/suse/sles/15.5/virt-launcher:1.1.1-150500.8.15.1
      - --exporter-image
      - registry.suse.com/suse/sles/15.5/virt-exportserver:1.1.1-150500.8.15.1
      - --port
      - "8443"
      - -v
      - "2"
      command:
      - virt-controller
      image: registry.suse.com/suse/sles/15.5/virt-controller:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          path: /healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 10
      name: virt-controller
      ports:
      - containerPort: 8443
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /leader
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 10
      resources:
        limits:
          cpu: 800m
          memory: 1300Mi
        requests:
          cpu: 10m
          memory: 275Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/virt-controller/certificates
        name: kubevirt-controller-certs
        readOnly: true
      - mountPath: /etc/virt-controller/exportca
        name: kubevirt-export-ca
        readOnly: true
      - mountPath: /profile-data
        name: profile-data
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c4lcr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 1e+09
    priorityClassName: kubevirt-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kubevirt-controller
    serviceAccountName: kubevirt-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kubevirt-controller-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-controller-certs
    - name: kubevirt-export-ca
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-export-ca
    - emptyDir: {}
      name: profile-data
    - name: kube-api-access-c4lcr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:43Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:57:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:57:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c0d1a9c5f61fcb4a4b27b9e30ab6f640947cbc1556966ac80321f4830470a669
      image: registry.suse.com/suse/sles/15.5/virt-controller:1.1.1-150500.8.15.1
      imageID: sha256:1eb4b14ae4e8100e1e4aa6fa87110417600a59b0dafe1c469c0a5175f7d8bcbc
      lastState: {}
      name: virt-controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:56:44Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.79
    podIPs:
    - ip: 10.52.0.79
    qosClass: Burstable
    startTime: "2024-08-06T01:56:43Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 52002280dc344ce8e87bed1ac7757e3d1845d50ecf1eb170c10095b3778e5ed7
      cni.projectcalico.org/podIP: 10.52.0.80/32
      cni.projectcalico.org/podIPs: 10.52.0.80/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.80"
            ],
            "default": true,
            "dns": {}
        }]
      kubevirt.io/install-strategy-identifier: 8c5c8323ebf23c689ce9bc87a13132d3fae18c7a
      kubevirt.io/install-strategy-registry: registry.suse.com/suse/sles/15.5
      kubevirt.io/install-strategy-version: 1.1.1-150500.8.15.1
    creationTimestamp: "2024-08-06T01:56:43Z"
    generateName: virt-controller-656bc79754-
    labels:
      app.kubernetes.io/component: kubevirt
      app.kubernetes.io/managed-by: virt-operator
      app.kubernetes.io/version: 1.1.1-150500.8.15.1
      kubevirt.io: virt-controller
      pod-template-hash: 656bc79754
      prometheus.kubevirt.io: "true"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubevirt.io/install-strategy-identifier: {}
            f:kubevirt.io/install-strategy-registry: {}
            f:kubevirt.io/install-strategy-version: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/version: {}
            f:kubevirt.io: {}
            f:pod-template-hash: {}
            f:prometheus.kubevirt.io: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"8f8ad8a0-cb1d-4a7c-a555-2332e6a59867"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:podAntiAffinity:
              .: {}
              f:preferredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"virt-controller"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:allowPrivilegeEscalation: {}
                f:capabilities:
                  .: {}
                  f:drop: {}
                f:seccompProfile:
                  .: {}
                  f:type: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/virt-controller/certificates"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/etc/virt-controller/exportca"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/profile-data"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext:
            .: {}
            f:runAsNonRoot: {}
            f:seccompProfile:
              .: {}
              f:type: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"kubevirt-controller-certs"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"kubevirt-export-ca"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"profile-data"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:56:43Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:44Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:44Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.80"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:57:03Z"
    name: virt-controller-656bc79754-vw5nq
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: virt-controller-656bc79754
      uid: 8f8ad8a0-cb1d-4a7c-a555-2332e6a59867
    resourceVersion: "8069"
    uid: 82a03e4e-9b65-4a2d-bb7d-b8bc71a77943
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: kubevirt.io
                operator: In
                values:
                - virt-controller
            topologyKey: kubernetes.io/hostname
          weight: 1
    containers:
    - args:
      - --launcher-image
      - registry.suse.com/suse/sles/15.5/virt-launcher:1.1.1-150500.8.15.1
      - --exporter-image
      - registry.suse.com/suse/sles/15.5/virt-exportserver:1.1.1-150500.8.15.1
      - --port
      - "8443"
      - -v
      - "2"
      command:
      - virt-controller
      image: registry.suse.com/suse/sles/15.5/virt-controller:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          path: /healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 10
      name: virt-controller
      ports:
      - containerPort: 8443
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /leader
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 10
      resources:
        limits:
          cpu: 800m
          memory: 1300Mi
        requests:
          cpu: 10m
          memory: 275Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/virt-controller/certificates
        name: kubevirt-controller-certs
        readOnly: true
      - mountPath: /etc/virt-controller/exportca
        name: kubevirt-export-ca
        readOnly: true
      - mountPath: /profile-data
        name: profile-data
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-v4lm4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 1e+09
    priorityClassName: kubevirt-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kubevirt-controller
    serviceAccountName: kubevirt-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kubevirt-controller-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-controller-certs
    - name: kubevirt-export-ca
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-export-ca
    - emptyDir: {}
      name: profile-data
    - name: kube-api-access-v4lm4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:43Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:57:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:57:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://59261aa8ebd14e822b9e03d315cc603521b8a0ba12b855c8be16dcf3923c742b
      image: registry.suse.com/suse/sles/15.5/virt-controller:1.1.1-150500.8.15.1
      imageID: sha256:1eb4b14ae4e8100e1e4aa6fa87110417600a59b0dafe1c469c0a5175f7d8bcbc
      lastState: {}
      name: virt-controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:56:44Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.80
    podIPs:
    - ip: 10.52.0.80
    qosClass: Burstable
    startTime: "2024-08-06T01:56:43Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 7d800b9585f670adeaa592df88df655c8813f67ac180b7dba06122f7965eba41
      cni.projectcalico.org/podIP: 10.52.3.10/32
      cni.projectcalico.org/podIPs: 10.52.3.10/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.3.10"
            ],
            "default": true,
            "dns": {}
        }]
      kubevirt.io/install-strategy-identifier: 8c5c8323ebf23c689ce9bc87a13132d3fae18c7a
      kubevirt.io/install-strategy-registry: registry.suse.com/suse/sles/15.5
      kubevirt.io/install-strategy-version: 1.1.1-150500.8.15.1
    creationTimestamp: "2024-08-06T02:15:35Z"
    generateName: virt-handler-
    labels:
      app.kubernetes.io/component: kubevirt
      app.kubernetes.io/managed-by: virt-operator
      app.kubernetes.io/version: 1.1.1-150500.8.15.1
      controller-revision-hash: 59d95c5f9
      kubevirt.io: virt-handler
      pod-template-generation: "1"
      prometheus.kubevirt.io: "true"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubevirt.io/install-strategy-identifier: {}
            f:kubevirt.io/install-strategy-registry: {}
            f:kubevirt.io/install-strategy-version: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/version: {}
            f:controller-revision-hash: {}
            f:kubevirt.io: {}
            f:pod-template-generation: {}
            f:prometheus.kubevirt.io: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"e604bd04-069e-40ae-8ba5-9edfe8b46362"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"virt-handler"}:
              .: {}
              f:args: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"MY_POD_IP"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
                f:seLinuxOptions:
                  .: {}
                  f:level: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/podinfo"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/etc/virt-handler/clientcertificates"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/etc/virt-handler/servercertificates"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/pods"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/profile-data"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/device-plugins"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/pods"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubevirt"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubevirt-node-labeller"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt-libvirt-runtimes"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt-private"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostPID: {}
          f:initContainers:
            .: {}
            k:{"name":"virt-launcher"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/var/lib/kubevirt-node-labeller"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"device-plugin"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubelet-pods"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubelet-pods-shortened"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubevirt-virt-handler-certs"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"kubevirt-virt-handler-server-certs"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"libvirt-runtimes"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"node-labeller"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"podinfo"}:
              .: {}
              f:downwardAPI:
                .: {}
                f:defaultMode: {}
                f:items: {}
              f:name: {}
            k:{"name":"profile-data"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
            k:{"name":"virt-lib-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"virt-private-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"virt-share-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:15:35Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:15:52Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:15:52Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.3.10"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:16:44Z"
    name: virt-handler-2kgsd
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: virt-handler
      uid: e604bd04-069e-40ae-8ba5-9edfe8b46362
    resourceVersion: "31158"
    uid: 8ff95102-4e31-4715-8bd2-05771774e0d4
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev7
    containers:
    - args:
      - --port
      - "8443"
      - --hostname-override
      - $(NODE_NAME)
      - --pod-ip-address
      - $(MY_POD_IP)
      - --max-metric-requests
      - "3"
      - --console-server-port
      - "8186"
      - --graceful-shutdown-seconds
      - "315"
      - -v
      - "2"
      command:
      - virt-handler
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: MY_POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: registry.suse.com/suse/sles/15.5/virt-handler:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 45
        successThreshold: 1
        timeoutSeconds: 10
      name: virt-handler
      ports:
      - containerPort: 8443
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 20
        successThreshold: 1
        timeoutSeconds: 10
      resources:
        limits:
          cpu: 700m
          memory: 1600Mi
        requests:
          cpu: 10m
          memory: 357Mi
      securityContext:
        privileged: true
        seLinuxOptions:
          level: s0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/virt-handler/clientcertificates
        name: kubevirt-virt-handler-certs
        readOnly: true
      - mountPath: /etc/virt-handler/servercertificates
        name: kubevirt-virt-handler-server-certs
        readOnly: true
      - mountPath: /profile-data
        name: profile-data
      - mountPath: /var/run/kubevirt-libvirt-runtimes
        name: libvirt-runtimes
      - mountPath: /var/run/kubevirt
        mountPropagation: Bidirectional
        name: virt-share-dir
      - mountPath: /var/lib/kubevirt
        name: virt-lib-dir
      - mountPath: /var/run/kubevirt-private
        name: virt-private-dir
      - mountPath: /var/lib/kubelet/device-plugins
        name: device-plugin
      - mountPath: /pods
        name: kubelet-pods-shortened
      - mountPath: /var/lib/kubelet/pods
        mountPropagation: Bidirectional
        name: kubelet-pods
      - mountPath: /var/lib/kubevirt-node-labeller
        name: node-labeller
      - mountPath: /etc/podinfo
        name: podinfo
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ttlqh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostPID: true
    initContainers:
    - args:
      - node-labeller.sh
      command:
      - /bin/sh
      - -c
      image: registry.suse.com/suse/sles/15.5/virt-launcher:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      name: virt-launcher
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubevirt-node-labeller
        name: node-labeller
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ttlqh
        readOnly: true
    nodeName: harvesterdev7
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 1e+09
    priorityClassName: kubevirt-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kubevirt-handler
    serviceAccountName: kubevirt-handler
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - name: kubevirt-virt-handler-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-handler-certs
    - name: kubevirt-virt-handler-server-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-handler-server-certs
    - emptyDir: {}
      name: profile-data
    - hostPath:
        path: /var/run/kubevirt-libvirt-runtimes
        type: "null"
      name: libvirt-runtimes
    - hostPath:
        path: /var/run/kubevirt
        type: "null"
      name: virt-share-dir
    - hostPath:
        path: /var/lib/kubevirt
        type: "null"
      name: virt-lib-dir
    - hostPath:
        path: /var/run/kubevirt-private
        type: "null"
      name: virt-private-dir
    - hostPath:
        path: /var/lib/kubelet/device-plugins
        type: "null"
      name: device-plugin
    - hostPath:
        path: /var/lib/kubelet/pods
        type: "null"
      name: kubelet-pods-shortened
    - hostPath:
        path: /var/lib/kubelet/pods
        type: "null"
      name: kubelet-pods
    - hostPath:
        path: /var/lib/kubevirt-node-labeller
        type: "null"
      name: node-labeller
    - downwardAPI:
        defaultMode: 420
        items:
        - fieldRef:
            apiVersion: v1
            fieldPath: metadata.annotations['k8s.v1.cni.cncf.io/network-status']
          path: network-status
      name: podinfo
    - name: kube-api-access-ttlqh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:16:11Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:16:44Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:16:44Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:15:35Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://dd39e95f5e8994dc2eafaa9a639bf91e5d9f240ad61b0dc4b355b8ed0fa64e18
      image: registry.suse.com/suse/sles/15.5/virt-handler:1.1.1-150500.8.15.1
      imageID: sha256:724be6af0f9abb85f4f77d6f877d069c748836d452a7479c11cc646e41787b38
      lastState: {}
      name: virt-handler
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:16:14Z"
    hostIP: 10.10.110.232
    initContainerStatuses:
    - containerID: containerd://9b632b54ae4d612bc23bd319e60e1a7f76c718fb971f1714dbd79f643b4aeb01
      image: registry.suse.com/suse/sles/15.5/virt-launcher:1.1.1-150500.8.15.1
      imageID: sha256:682a2559c2375c12ba54baee569f714b01c518b8b9153b2a28c2494dd1f102d5
      lastState: {}
      name: virt-launcher
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: containerd://9b632b54ae4d612bc23bd319e60e1a7f76c718fb971f1714dbd79f643b4aeb01
          exitCode: 0
          finishedAt: "2024-08-06T02:16:03Z"
          reason: Completed
          startedAt: "2024-08-06T02:16:01Z"
    phase: Running
    podIP: 10.52.3.10
    podIPs:
    - ip: 10.52.3.10
    qosClass: Burstable
    startTime: "2024-08-06T02:15:35Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 8c879801cdd289bb1c5a40db9a74e3b929e5cfcbcd0cc4be1aba1396fed533ad
      cni.projectcalico.org/podIP: 10.52.1.6/32
      cni.projectcalico.org/podIPs: 10.52.1.6/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.1.6"
            ],
            "default": true,
            "dns": {}
        }]
      kubevirt.io/install-strategy-identifier: 8c5c8323ebf23c689ce9bc87a13132d3fae18c7a
      kubevirt.io/install-strategy-registry: registry.suse.com/suse/sles/15.5
      kubevirt.io/install-strategy-version: 1.1.1-150500.8.15.1
    creationTimestamp: "2024-08-06T02:11:24Z"
    generateName: virt-handler-
    labels:
      app.kubernetes.io/component: kubevirt
      app.kubernetes.io/managed-by: virt-operator
      app.kubernetes.io/version: 1.1.1-150500.8.15.1
      controller-revision-hash: 59d95c5f9
      kubevirt.io: virt-handler
      pod-template-generation: "1"
      prometheus.kubevirt.io: "true"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubevirt.io/install-strategy-identifier: {}
            f:kubevirt.io/install-strategy-registry: {}
            f:kubevirt.io/install-strategy-version: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/version: {}
            f:controller-revision-hash: {}
            f:kubevirt.io: {}
            f:pod-template-generation: {}
            f:prometheus.kubevirt.io: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"e604bd04-069e-40ae-8ba5-9edfe8b46362"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"virt-handler"}:
              .: {}
              f:args: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"MY_POD_IP"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
                f:seLinuxOptions:
                  .: {}
                  f:level: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/podinfo"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/etc/virt-handler/clientcertificates"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/etc/virt-handler/servercertificates"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/pods"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/profile-data"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/device-plugins"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/pods"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubevirt"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubevirt-node-labeller"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt-libvirt-runtimes"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt-private"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostPID: {}
          f:initContainers:
            .: {}
            k:{"name":"virt-launcher"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/var/lib/kubevirt-node-labeller"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"device-plugin"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubelet-pods"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubelet-pods-shortened"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubevirt-virt-handler-certs"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"kubevirt-virt-handler-server-certs"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"libvirt-runtimes"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"node-labeller"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"podinfo"}:
              .: {}
              f:downwardAPI:
                .: {}
                f:defaultMode: {}
                f:items: {}
              f:name: {}
            k:{"name":"profile-data"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
            k:{"name":"virt-lib-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"virt-private-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"virt-share-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:11:24Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:11:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.1.6"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:12:18Z"
    name: virt-handler-6hm2s
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: virt-handler
      uid: e604bd04-069e-40ae-8ba5-9edfe8b46362
    resourceVersion: "24415"
    uid: 778385be-cb61-41d6-9d0b-010bc4ab7669
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev2
    containers:
    - args:
      - --port
      - "8443"
      - --hostname-override
      - $(NODE_NAME)
      - --pod-ip-address
      - $(MY_POD_IP)
      - --max-metric-requests
      - "3"
      - --console-server-port
      - "8186"
      - --graceful-shutdown-seconds
      - "315"
      - -v
      - "2"
      command:
      - virt-handler
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: MY_POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: registry.suse.com/suse/sles/15.5/virt-handler:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 45
        successThreshold: 1
        timeoutSeconds: 10
      name: virt-handler
      ports:
      - containerPort: 8443
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 20
        successThreshold: 1
        timeoutSeconds: 10
      resources:
        limits:
          cpu: 700m
          memory: 1600Mi
        requests:
          cpu: 10m
          memory: 357Mi
      securityContext:
        privileged: true
        seLinuxOptions:
          level: s0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/virt-handler/clientcertificates
        name: kubevirt-virt-handler-certs
        readOnly: true
      - mountPath: /etc/virt-handler/servercertificates
        name: kubevirt-virt-handler-server-certs
        readOnly: true
      - mountPath: /profile-data
        name: profile-data
      - mountPath: /var/run/kubevirt-libvirt-runtimes
        name: libvirt-runtimes
      - mountPath: /var/run/kubevirt
        mountPropagation: Bidirectional
        name: virt-share-dir
      - mountPath: /var/lib/kubevirt
        name: virt-lib-dir
      - mountPath: /var/run/kubevirt-private
        name: virt-private-dir
      - mountPath: /var/lib/kubelet/device-plugins
        name: device-plugin
      - mountPath: /pods
        name: kubelet-pods-shortened
      - mountPath: /var/lib/kubelet/pods
        mountPropagation: Bidirectional
        name: kubelet-pods
      - mountPath: /var/lib/kubevirt-node-labeller
        name: node-labeller
      - mountPath: /etc/podinfo
        name: podinfo
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-j5kpq
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostPID: true
    initContainers:
    - args:
      - node-labeller.sh
      command:
      - /bin/sh
      - -c
      image: registry.suse.com/suse/sles/15.5/virt-launcher:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      name: virt-launcher
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubevirt-node-labeller
        name: node-labeller
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-j5kpq
        readOnly: true
    nodeName: harvesterdev2
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 1e+09
    priorityClassName: kubevirt-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kubevirt-handler
    serviceAccountName: kubevirt-handler
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - name: kubevirt-virt-handler-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-handler-certs
    - name: kubevirt-virt-handler-server-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-handler-server-certs
    - emptyDir: {}
      name: profile-data
    - hostPath:
        path: /var/run/kubevirt-libvirt-runtimes
        type: "null"
      name: libvirt-runtimes
    - hostPath:
        path: /var/run/kubevirt
        type: "null"
      name: virt-share-dir
    - hostPath:
        path: /var/lib/kubevirt
        type: "null"
      name: virt-lib-dir
    - hostPath:
        path: /var/run/kubevirt-private
        type: "null"
      name: virt-private-dir
    - hostPath:
        path: /var/lib/kubelet/device-plugins
        type: "null"
      name: device-plugin
    - hostPath:
        path: /var/lib/kubelet/pods
        type: "null"
      name: kubelet-pods-shortened
    - hostPath:
        path: /var/lib/kubelet/pods
        type: "null"
      name: kubelet-pods
    - hostPath:
        path: /var/lib/kubevirt-node-labeller
        type: "null"
      name: node-labeller
    - downwardAPI:
        defaultMode: 420
        items:
        - fieldRef:
            apiVersion: v1
            fieldPath: metadata.annotations['k8s.v1.cni.cncf.io/network-status']
          path: network-status
      name: podinfo
    - name: kube-api-access-j5kpq
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:47Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:12:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:12:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:11:24Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4256a0df68449b1c8a79bacaa3cdd7a95d2ae6bb9f62873dec7fa31bf156eeaf
      image: registry.suse.com/suse/sles/15.5/virt-handler:1.1.1-150500.8.15.1
      imageID: sha256:724be6af0f9abb85f4f77d6f877d069c748836d452a7479c11cc646e41787b38
      lastState: {}
      name: virt-handler
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:11:48Z"
    hostIP: 10.10.110.71
    initContainerStatuses:
    - containerID: containerd://933e27f0c8173a018aea0620a68970a2abe8b567c3f039e76c71018a941c2c20
      image: registry.suse.com/suse/sles/15.5/virt-launcher:1.1.1-150500.8.15.1
      imageID: sha256:682a2559c2375c12ba54baee569f714b01c518b8b9153b2a28c2494dd1f102d5
      lastState: {}
      name: virt-launcher
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: containerd://933e27f0c8173a018aea0620a68970a2abe8b567c3f039e76c71018a941c2c20
          exitCode: 0
          finishedAt: "2024-08-06T02:11:44Z"
          reason: Completed
          startedAt: "2024-08-06T02:11:42Z"
    phase: Running
    podIP: 10.52.1.6
    podIPs:
    - ip: 10.52.1.6
    qosClass: Burstable
    startTime: "2024-08-06T02:11:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: f021007b3fbc0415f8e44cbb4830dfdad5fe1f96d1099ffb3d8d8ca6ac9ba58f
      cni.projectcalico.org/podIP: 10.52.2.7/32
      cni.projectcalico.org/podIPs: 10.52.2.7/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.2.7"
            ],
            "default": true,
            "dns": {}
        }]
      kubevirt.io/install-strategy-identifier: 8c5c8323ebf23c689ce9bc87a13132d3fae18c7a
      kubevirt.io/install-strategy-registry: registry.suse.com/suse/sles/15.5
      kubevirt.io/install-strategy-version: 1.1.1-150500.8.15.1
    creationTimestamp: "2024-08-06T02:13:16Z"
    generateName: virt-handler-
    labels:
      app.kubernetes.io/component: kubevirt
      app.kubernetes.io/managed-by: virt-operator
      app.kubernetes.io/version: 1.1.1-150500.8.15.1
      controller-revision-hash: 59d95c5f9
      kubevirt.io: virt-handler
      pod-template-generation: "1"
      prometheus.kubevirt.io: "true"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubevirt.io/install-strategy-identifier: {}
            f:kubevirt.io/install-strategy-registry: {}
            f:kubevirt.io/install-strategy-version: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/version: {}
            f:controller-revision-hash: {}
            f:kubevirt.io: {}
            f:pod-template-generation: {}
            f:prometheus.kubevirt.io: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"e604bd04-069e-40ae-8ba5-9edfe8b46362"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"virt-handler"}:
              .: {}
              f:args: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"MY_POD_IP"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
                f:seLinuxOptions:
                  .: {}
                  f:level: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/podinfo"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/etc/virt-handler/clientcertificates"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/etc/virt-handler/servercertificates"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/pods"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/profile-data"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/device-plugins"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/pods"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubevirt"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubevirt-node-labeller"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt-libvirt-runtimes"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt-private"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostPID: {}
          f:initContainers:
            .: {}
            k:{"name":"virt-launcher"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/var/lib/kubevirt-node-labeller"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"device-plugin"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubelet-pods"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubelet-pods-shortened"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubevirt-virt-handler-certs"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"kubevirt-virt-handler-server-certs"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"libvirt-runtimes"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"node-labeller"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"podinfo"}:
              .: {}
              f:downwardAPI:
                .: {}
                f:defaultMode: {}
                f:items: {}
              f:name: {}
            k:{"name":"profile-data"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
            k:{"name":"virt-lib-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"virt-private-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"virt-share-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T02:13:16Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:30Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T02:13:30Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.2.7"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T02:14:07Z"
    name: virt-handler-dfvlr
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: virt-handler
      uid: e604bd04-069e-40ae-8ba5-9edfe8b46362
    resourceVersion: "27596"
    uid: 37432f80-ac5d-4262-b009-9ff911875384
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev3
    containers:
    - args:
      - --port
      - "8443"
      - --hostname-override
      - $(NODE_NAME)
      - --pod-ip-address
      - $(MY_POD_IP)
      - --max-metric-requests
      - "3"
      - --console-server-port
      - "8186"
      - --graceful-shutdown-seconds
      - "315"
      - -v
      - "2"
      command:
      - virt-handler
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: MY_POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: registry.suse.com/suse/sles/15.5/virt-handler:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 45
        successThreshold: 1
        timeoutSeconds: 10
      name: virt-handler
      ports:
      - containerPort: 8443
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 20
        successThreshold: 1
        timeoutSeconds: 10
      resources:
        limits:
          cpu: 700m
          memory: 1600Mi
        requests:
          cpu: 10m
          memory: 357Mi
      securityContext:
        privileged: true
        seLinuxOptions:
          level: s0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/virt-handler/clientcertificates
        name: kubevirt-virt-handler-certs
        readOnly: true
      - mountPath: /etc/virt-handler/servercertificates
        name: kubevirt-virt-handler-server-certs
        readOnly: true
      - mountPath: /profile-data
        name: profile-data
      - mountPath: /var/run/kubevirt-libvirt-runtimes
        name: libvirt-runtimes
      - mountPath: /var/run/kubevirt
        mountPropagation: Bidirectional
        name: virt-share-dir
      - mountPath: /var/lib/kubevirt
        name: virt-lib-dir
      - mountPath: /var/run/kubevirt-private
        name: virt-private-dir
      - mountPath: /var/lib/kubelet/device-plugins
        name: device-plugin
      - mountPath: /pods
        name: kubelet-pods-shortened
      - mountPath: /var/lib/kubelet/pods
        mountPropagation: Bidirectional
        name: kubelet-pods
      - mountPath: /var/lib/kubevirt-node-labeller
        name: node-labeller
      - mountPath: /etc/podinfo
        name: podinfo
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hn224
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostPID: true
    initContainers:
    - args:
      - node-labeller.sh
      command:
      - /bin/sh
      - -c
      image: registry.suse.com/suse/sles/15.5/virt-launcher:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      name: virt-launcher
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubevirt-node-labeller
        name: node-labeller
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hn224
        readOnly: true
    nodeName: harvesterdev3
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 1e+09
    priorityClassName: kubevirt-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kubevirt-handler
    serviceAccountName: kubevirt-handler
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - name: kubevirt-virt-handler-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-handler-certs
    - name: kubevirt-virt-handler-server-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-handler-server-certs
    - emptyDir: {}
      name: profile-data
    - hostPath:
        path: /var/run/kubevirt-libvirt-runtimes
        type: "null"
      name: libvirt-runtimes
    - hostPath:
        path: /var/run/kubevirt
        type: "null"
      name: virt-share-dir
    - hostPath:
        path: /var/lib/kubevirt
        type: "null"
      name: virt-lib-dir
    - hostPath:
        path: /var/run/kubevirt-private
        type: "null"
      name: virt-private-dir
    - hostPath:
        path: /var/lib/kubelet/device-plugins
        type: "null"
      name: device-plugin
    - hostPath:
        path: /var/lib/kubelet/pods
        type: "null"
      name: kubelet-pods-shortened
    - hostPath:
        path: /var/lib/kubelet/pods
        type: "null"
      name: kubelet-pods
    - hostPath:
        path: /var/lib/kubevirt-node-labeller
        type: "null"
      name: node-labeller
    - downwardAPI:
        defaultMode: 420
        items:
        - fieldRef:
            apiVersion: v1
            fieldPath: metadata.annotations['k8s.v1.cni.cncf.io/network-status']
          path: network-status
      name: podinfo
    - name: kube-api-access-hn224
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:36Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:14:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:14:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T02:13:16Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://ba38453573a68f93d1f0430c5db731dc9c16de1936f5be056e577cff87f20399
      image: registry.suse.com/suse/sles/15.5/virt-handler:1.1.1-150500.8.15.1
      imageID: sha256:724be6af0f9abb85f4f77d6f877d069c748836d452a7479c11cc646e41787b38
      lastState: {}
      name: virt-handler
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T02:13:38Z"
    hostIP: 10.10.110.61
    initContainerStatuses:
    - containerID: containerd://c20478129dac4dcef7cf1f3b821beb8c4d77f879e61e1ecb82af6d66dbf9e930
      image: registry.suse.com/suse/sles/15.5/virt-launcher:1.1.1-150500.8.15.1
      imageID: sha256:682a2559c2375c12ba54baee569f714b01c518b8b9153b2a28c2494dd1f102d5
      lastState: {}
      name: virt-launcher
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: containerd://c20478129dac4dcef7cf1f3b821beb8c4d77f879e61e1ecb82af6d66dbf9e930
          exitCode: 0
          finishedAt: "2024-08-06T02:13:36Z"
          reason: Completed
          startedAt: "2024-08-06T02:13:33Z"
    phase: Running
    podIP: 10.52.2.7
    podIPs:
    - ip: 10.52.2.7
    qosClass: Burstable
    startTime: "2024-08-06T02:13:16Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: d16f109950471bdd147f9170fc96bade0dbbd84df3d2371239e67c3fa0f83f77
      cni.projectcalico.org/podIP: 10.52.0.78/32
      cni.projectcalico.org/podIPs: 10.52.0.78/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.78"
            ],
            "default": true,
            "dns": {}
        }]
      kubevirt.io/install-strategy-identifier: 8c5c8323ebf23c689ce9bc87a13132d3fae18c7a
      kubevirt.io/install-strategy-registry: registry.suse.com/suse/sles/15.5
      kubevirt.io/install-strategy-version: 1.1.1-150500.8.15.1
    creationTimestamp: "2024-08-06T01:56:43Z"
    generateName: virt-handler-
    labels:
      app.kubernetes.io/component: kubevirt
      app.kubernetes.io/managed-by: virt-operator
      app.kubernetes.io/version: 1.1.1-150500.8.15.1
      controller-revision-hash: 59d95c5f9
      kubevirt.io: virt-handler
      pod-template-generation: "1"
      prometheus.kubevirt.io: "true"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubevirt.io/install-strategy-identifier: {}
            f:kubevirt.io/install-strategy-registry: {}
            f:kubevirt.io/install-strategy-version: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/version: {}
            f:controller-revision-hash: {}
            f:kubevirt.io: {}
            f:pod-template-generation: {}
            f:prometheus.kubevirt.io: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"e604bd04-069e-40ae-8ba5-9edfe8b46362"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"virt-handler"}:
              .: {}
              f:args: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"MY_POD_IP"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
                k:{"name":"NODE_NAME"}:
                  .: {}
                  f:name: {}
                  f:valueFrom:
                    .: {}
                    f:fieldRef: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
                f:seLinuxOptions:
                  .: {}
                  f:level: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/podinfo"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/etc/virt-handler/clientcertificates"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/etc/virt-handler/servercertificates"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/pods"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/profile-data"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/device-plugins"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubelet/pods"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubevirt"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/lib/kubevirt-node-labeller"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt"}:
                  .: {}
                  f:mountPath: {}
                  f:mountPropagation: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt-libvirt-runtimes"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/var/run/kubevirt-private"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostPID: {}
          f:initContainers:
            .: {}
            k:{"name":"virt-launcher"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/var/lib/kubevirt-node-labeller"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"device-plugin"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubelet-pods"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubelet-pods-shortened"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"kubevirt-virt-handler-certs"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"kubevirt-virt-handler-server-certs"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"libvirt-runtimes"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"node-labeller"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"podinfo"}:
              .: {}
              f:downwardAPI:
                .: {}
                f:defaultMode: {}
                f:items: {}
              f:name: {}
            k:{"name":"profile-data"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
            k:{"name":"virt-lib-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"virt-private-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
            k:{"name":"virt-share-dir"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:56:43Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:44Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:56:44Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:initContainerStatuses: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.78"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:57:23Z"
    name: virt-handler-xvqn7
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: virt-handler
      uid: e604bd04-069e-40ae-8ba5-9edfe8b46362
    resourceVersion: "9013"
    uid: b04071ce-cd85-43e7-93ac-9d6ae0e9dcb3
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - harvesterdev1
    containers:
    - args:
      - --port
      - "8443"
      - --hostname-override
      - $(NODE_NAME)
      - --pod-ip-address
      - $(MY_POD_IP)
      - --max-metric-requests
      - "3"
      - --console-server-port
      - "8186"
      - --graceful-shutdown-seconds
      - "315"
      - -v
      - "2"
      command:
      - virt-handler
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: MY_POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: registry.suse.com/suse/sles/15.5/virt-handler:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 45
        successThreshold: 1
        timeoutSeconds: 10
      name: virt-handler
      ports:
      - containerPort: 8443
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 15
        periodSeconds: 20
        successThreshold: 1
        timeoutSeconds: 10
      resources:
        limits:
          cpu: 700m
          memory: 1600Mi
        requests:
          cpu: 10m
          memory: 357Mi
      securityContext:
        privileged: true
        seLinuxOptions:
          level: s0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/virt-handler/clientcertificates
        name: kubevirt-virt-handler-certs
        readOnly: true
      - mountPath: /etc/virt-handler/servercertificates
        name: kubevirt-virt-handler-server-certs
        readOnly: true
      - mountPath: /profile-data
        name: profile-data
      - mountPath: /var/run/kubevirt-libvirt-runtimes
        name: libvirt-runtimes
      - mountPath: /var/run/kubevirt
        mountPropagation: Bidirectional
        name: virt-share-dir
      - mountPath: /var/lib/kubevirt
        name: virt-lib-dir
      - mountPath: /var/run/kubevirt-private
        name: virt-private-dir
      - mountPath: /var/lib/kubelet/device-plugins
        name: device-plugin
      - mountPath: /pods
        name: kubelet-pods-shortened
      - mountPath: /var/lib/kubelet/pods
        mountPropagation: Bidirectional
        name: kubelet-pods
      - mountPath: /var/lib/kubevirt-node-labeller
        name: node-labeller
      - mountPath: /etc/podinfo
        name: podinfo
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bx4hx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostPID: true
    initContainers:
    - args:
      - node-labeller.sh
      command:
      - /bin/sh
      - -c
      image: registry.suse.com/suse/sles/15.5/virt-launcher:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      name: virt-launcher
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kubevirt-node-labeller
        name: node-labeller
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bx4hx
        readOnly: true
    nodeName: harvesterdev1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 1e+09
    priorityClassName: kubevirt-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kubevirt-handler
    serviceAccountName: kubevirt-handler
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - name: kubevirt-virt-handler-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-handler-certs
    - name: kubevirt-virt-handler-server-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-virt-handler-server-certs
    - emptyDir: {}
      name: profile-data
    - hostPath:
        path: /var/run/kubevirt-libvirt-runtimes
        type: "null"
      name: libvirt-runtimes
    - hostPath:
        path: /var/run/kubevirt
        type: "null"
      name: virt-share-dir
    - hostPath:
        path: /var/lib/kubevirt
        type: "null"
      name: virt-lib-dir
    - hostPath:
        path: /var/run/kubevirt-private
        type: "null"
      name: virt-private-dir
    - hostPath:
        path: /var/lib/kubelet/device-plugins
        type: "null"
      name: device-plugin
    - hostPath:
        path: /var/lib/kubelet/pods
        type: "null"
      name: kubelet-pods-shortened
    - hostPath:
        path: /var/lib/kubelet/pods
        type: "null"
      name: kubelet-pods
    - hostPath:
        path: /var/lib/kubevirt-node-labeller
        type: "null"
      name: node-labeller
    - downwardAPI:
        defaultMode: 420
        items:
        - fieldRef:
            apiVersion: v1
            fieldPath: metadata.annotations['k8s.v1.cni.cncf.io/network-status']
          path: network-status
      name: podinfo
    - name: kube-api-access-bx4hx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:50Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:57:23Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:57:23Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:56:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://b79ce5e30d43679a2ab88d255998e04ca968203e50a4808998fe1da315d88fd1
      image: registry.suse.com/suse/sles/15.5/virt-handler:1.1.1-150500.8.15.1
      imageID: sha256:724be6af0f9abb85f4f77d6f877d069c748836d452a7479c11cc646e41787b38
      lastState: {}
      name: virt-handler
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:56:51Z"
    hostIP: 10.10.110.11
    initContainerStatuses:
    - containerID: containerd://c48daf69c1629f374140f15c02cd69e6b22406d33595f690342a7c5e30983e9d
      image: registry.suse.com/suse/sles/15.5/virt-launcher:1.1.1-150500.8.15.1
      imageID: sha256:682a2559c2375c12ba54baee569f714b01c518b8b9153b2a28c2494dd1f102d5
      lastState: {}
      name: virt-launcher
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: containerd://c48daf69c1629f374140f15c02cd69e6b22406d33595f690342a7c5e30983e9d
          exitCode: 0
          finishedAt: "2024-08-06T01:56:49Z"
          reason: Completed
          startedAt: "2024-08-06T01:56:46Z"
    phase: Running
    podIP: 10.52.0.78
    podIPs:
    - ip: 10.52.0.78
    qosClass: Burstable
    startTime: "2024-08-06T01:56:43Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 2fb608e03582cbd52c559717c3ac91501890103963ba2f504af228017b9fa3cc
      cni.projectcalico.org/podIP: 10.52.0.40/32
      cni.projectcalico.org/podIPs: 10.52.0.40/32
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "k8s-pod-network",
            "ips": [
                "10.52.0.40"
            ],
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-08-06T01:55:39Z"
    generateName: virt-operator-74c7f9696d-
    labels:
      app.kubernetes.io/component: operator
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: virt-operator
      app.kubernetes.io/part-of: kubevirt-operator
      app.kubernetes.io/version: 0.30.x
      helm.sh/chart: kubevirt-operator-0.2.0
      helm.sh/release: harvester
      kubevirt.io: virt-operator
      pod-template-hash: 74c7f9696d
      prometheus.kubevirt.io: "true"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/name: {}
            f:app.kubernetes.io/part-of: {}
            f:app.kubernetes.io/version: {}
            f:helm.sh/chart: {}
            f:helm.sh/release: {}
            f:kubevirt.io: {}
            f:pod-template-hash: {}
            f:prometheus.kubevirt.io: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"32d9bf81-4f2b-4db1-8cbb-ab90e239ebf8"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
            f:podAntiAffinity:
              .: {}
              f:preferredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"virt-operator"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"OPERATOR_IMAGE"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":8443,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":8444,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:limits:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/virt-operator/certificates"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
                k:{"mountPath":"/profile-data"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext:
            .: {}
            f:runAsNonRoot: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:volumes:
            .: {}
            k:{"name":"kubevirt-operator-certs"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:optional: {}
                f:secretName: {}
            k:{"name":"profile-data"}:
              .: {}
              f:emptyDir: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-08-06T01:55:39Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cni.projectcalico.org/containerID: {}
            f:cni.projectcalico.org/podIP: {}
            f:cni.projectcalico.org/podIPs: {}
      manager: calico
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:40Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.52.0.40"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-08-06T01:55:54Z"
    name: virt-operator-74c7f9696d-pc6tw
    namespace: harvester-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: virt-operator-74c7f9696d
      uid: 32d9bf81-4f2b-4db1-8cbb-ab90e239ebf8
    resourceVersion: "5552"
    uid: 63efab56-21f2-4c7f-9663-ed3eb193ba4d
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: In
              values:
              - linux
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: kubevirt.io
                operator: In
                values:
                - virt-operator
            topologyKey: kubernetes.io/hostname
          weight: 1
    containers:
    - command:
      - virt-operator
      - --port
      - "8443"
      - -v
      - "2"
      env:
      - name: OPERATOR_IMAGE
        value: registry.suse.com/suse/sles/15.5/virt-operator:1.1.1-150500.8.15.1
      image: registry.suse.com/suse/sles/15.5/virt-operator:1.1.1-150500.8.15.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /metrics
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 30
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 10
      name: virt-operator
      ports:
      - containerPort: 8443
        name: metrics
        protocol: TCP
      - containerPort: 8444
        name: webhooks
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /metrics
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 10
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 250m
          memory: 256Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/virt-operator/certificates
        name: kubevirt-operator-certs
        readOnly: true
      - mountPath: /profile-data
        name: profile-data
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tf8v9
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: harvesterdev1
    preemptionPolicy: PreemptLowerPriority
    priority: 1e+09
    priorityClassName: kubevirt-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
    serviceAccount: kubevirt-operator
    serviceAccountName: kubevirt-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kubevirt-operator-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: kubevirt-operator-certs
    - emptyDir: {}
      name: profile-data
    - name: kube-api-access-tf8v9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:54Z"
      status: "True"
      type: Ready
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:54Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: "null"
      lastTransitionTime: "2024-08-06T01:55:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://860873b00acb63a33df7c52d63ce9e2ec9e475bdbb9a745b706cd93357d01101
      image: registry.suse.com/suse/sles/15.5/virt-operator:1.1.1-150500.8.15.1
      imageID: sha256:87986b2b1ceb84f13cc098e40a3ecc0001e47d65f593761f07118990337fe7fe
      lastState: {}
      name: virt-operator
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-08-06T01:55:42Z"
    hostIP: 10.10.110.11
    phase: Running
    podIP: 10.52.0.40
    podIPs:
    - ip: 10.52.0.40
    qosClass: Burstable
    startTime: "2024-08-06T01:55:39Z"
kind: List
metadata:
  resourceVersion: "770255"
